{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd5d68a-4289-41f7-838e-495ecf0d995d",
   "metadata": {
    "id": "4fd5d68a-4289-41f7-838e-495ecf0d995d",
    "tags": []
   },
   "source": [
    "## Training GPT-2 Model on Path Sequences to Perform Navigation Tasks\n",
    "This script trains/fine-tunes a GPT-2 model on path sequences in artificial grid environments with randomly generated nouns representing locations on a grid.\n",
    "\n",
    "This script has the following parts:\n",
    "\n",
    "* Generation of path sequences in artificial environments\n",
    "Optimal paths and suboptimal paths are separately generated in the training data. For optimal paths, the shortest paths from any starting and ending locations are generated, therefore the training data includes all the possible optimal paths. For suboptimal paths, only a subset is randomly selected, because the number of possible suboptimal paths greatly outnumber optimal paths as the grid size increases. \n",
    "\n",
    "* Train/fine-tune GPT-2 model on the generated path sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1a12d-ed03-4a17-960d-0a6863681170",
   "metadata": {
    "id": "9ac1a12d-ed03-4a17-960d-0a6863681170"
   },
   "source": [
    "#### Installation / imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa35db41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25958,
     "status": "ok",
     "timestamp": 1718189337133,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "fa35db41",
    "outputId": "ff0c94f9-a738-4a25-e9fd-6c540bf3027f"
   },
   "outputs": [],
   "source": [
    "# # Connect to Google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd \"/content/drive/My Drive/modelling_spatial_navigation/gpt2small_dual_mode_v12_6000_4by4grids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658f7a8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718189337134,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "658f7a8e",
    "outputId": "5eee6ddb-711a-4225-edad-7d6a0d3a2ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/bin/python\n",
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/bin/pip\n",
      "Python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "# python and pip version check\n",
    "! which python\n",
    "! which pip\n",
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05917c15-2dc4-4d88-9ab0-5135187faaa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115609,
     "status": "ok",
     "timestamp": 1718189452740,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "05917c15-2dc4-4d88-9ab0-5135187faaa3",
    "outputId": "41517c41-e718-4497-f78f-4bf66f1cc9d5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-w6wu31ub\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-w6wu31ub\n",
      "  Resolved https://github.com/huggingface/transformers to commit d7b87b415a5dd4a3152051e1a0abd098a02c5bfa\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (0.32.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from transformers==4.53.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.0.dev0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->transformers==4.53.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->transformers==4.53.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->transformers==4.53.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->transformers==4.53.0.dev0) (2025.4.26)\n",
      "Requirement already satisfied: accelerate in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (1.7.0)\n",
      "Requirement already satisfied: evaluate in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: wonderwords in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (2.2.0)\n",
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (0.32.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: dill in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: regex in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from simpletransformers) (2024.11.6)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from simpletransformers) (4.53.0.dev0)\n",
      "Requirement already satisfied: scipy in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from simpletransformers) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from simpletransformers) (1.6.1)\n",
      "Collecting seqeval (from simpletransformers)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard (from simpletransformers)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorboardx (from simpletransformers)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tokenizers in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from simpletransformers) (0.21.1)\n",
      "Collecting wandb>=0.10.32 (from simpletransformers)\n",
      "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting streamlit (from simpletransformers)\n",
      "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting sentencepiece (from simpletransformers)\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (53.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting eval-type-backport (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from wandb>=0.10.32->simpletransformers) (4.3.8)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading setproctitle-1.3.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb>=0.10.32->simpletransformers)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb>=0.10.32->simpletransformers)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb>=0.10.32->simpletransformers)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from scikit-learn->simpletransformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from scikit-learn->simpletransformers) (3.6.0)\n",
      "Collecting altair<6,>=4.0 (from streamlit->simpletransformers)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit->simpletransformers)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit->simpletransformers)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting packaging>=20.0 (from accelerate)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from streamlit->simpletransformers) (11.2.1)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit->simpletransformers)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit->simpletransformers)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit->simpletransformers)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from streamlit->simpletransformers) (6.5.1)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Downloading narwhals-1.42.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Downloading rpds_py-0.25.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->simpletransformers)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->simpletransformers)\n",
      "  Downloading grpcio-1.73.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->simpletransformers)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->simpletransformers)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->simpletransformers)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->simpletransformers) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->simpletransformers) (3.22.0)\n",
      "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
      "Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-1.42.0-py3-none-any.whl (359 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.25.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.73.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=21c138823e41a8d714adae8892768fcebe63fa9bfd4863b8ebcc1cb3c4532c62\n",
      "  Stored in directory: /cs/student/msc/aibh/2024/cbaumgar/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "Successfully built seqeval\n",
      "Installing collected packages: sentencepiece, werkzeug, watchdog, typing-inspection, toml, tensorboard-data-server, tenacity, smmap, setproctitle, sentry-sdk, rpds-py, pydantic-core, protobuf, packaging, narwhals, grpcio, eval-type-backport, click, cachetools, blinker, annotated-types, absl-py, tensorboardx, referencing, pydeck, pydantic, markdown, gitdb, tensorboard, seqeval, jsonschema-specifications, gitpython, wandb, jsonschema, altair, streamlit, simpletransformers\n",
      "\u001b[2K  Attempting uninstall: packagingm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [protobuf]core]ta-server]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling packaging-25.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/37\u001b[0m [simpletransformers]impletransformers]ations]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.0 altair-5.5.0 annotated-types-0.7.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.44 grpcio-1.73.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 markdown-3.8 narwhals-1.42.0 packaging-24.2 protobuf-6.31.1 pydantic-2.11.5 pydantic-core-2.33.2 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.25.1 sentencepiece-0.2.0 sentry-sdk-2.29.1 seqeval-1.2.2 setproctitle-1.3.6 simpletransformers-0.70.1 smmap-5.0.2 streamlit-1.45.1 tenacity-9.1.2 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardx-2.6.2.2 toml-0.10.2 typing-inspection-0.4.1 wandb-0.20.1 watchdog-6.0.0 werkzeug-3.1.3\n",
      "Requirement already satisfied: huggingface_hub in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (0.32.1)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib/python3.9/site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Downloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.32.1\n",
      "    Uninstalling huggingface-hub-0.32.1:\n",
      "      Successfully uninstalled huggingface-hub-0.32.1\n",
      "Successfully installed huggingface_hub-0.32.4\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/huggingface/transformers --upgrade\n",
    "! pip install accelerate evaluate wonderwords simpletransformers --upgrade\n",
    "! pip install huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83366812-1e46-4304-a690-d3cadf2cf35e",
   "metadata": {
    "id": "83366812-1e46-4304-a690-d3cadf2cf35e"
   },
   "source": [
    "### Generate training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b93d3f-dd38-40bf-a3e5-cfce37e89d6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9539,
     "status": "ok",
     "timestamp": 1715295219867,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -480
    },
    "id": "a1b93d3f-dd38-40bf-a3e5-cfce37e89d6c",
    "outputId": "b73380bc-a088-4dc0-9ddb-64484860c646",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 completed.\n",
      "Iteration 100 completed.\n",
      "Iteration 200 completed.\n",
      "Iteration 300 completed.\n",
      "Iteration 400 completed.\n",
      "Iteration 500 completed.\n",
      "Iteration 600 completed.\n",
      "Iteration 700 completed.\n",
      "Iteration 800 completed.\n",
      "Iteration 900 completed.\n",
      "Iteration 1000 completed.\n",
      "Iteration 1100 completed.\n",
      "Iteration 1200 completed.\n",
      "Iteration 1300 completed.\n",
      "Iteration 1400 completed.\n",
      "Iteration 1500 completed.\n",
      "Iteration 1600 completed.\n",
      "Iteration 1700 completed.\n",
      "Iteration 1800 completed.\n",
      "Iteration 1900 completed.\n",
      "Iteration 2000 completed.\n",
      "Iteration 2100 completed.\n",
      "Iteration 2200 completed.\n",
      "Iteration 2300 completed.\n",
      "Iteration 2400 completed.\n",
      "Iteration 2500 completed.\n",
      "Iteration 2600 completed.\n",
      "Iteration 2700 completed.\n",
      "Iteration 2800 completed.\n",
      "Iteration 2900 completed.\n",
      "\n",
      "4464000 paths generated for pre-training.\n",
      "44640 paths generated for testing.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "Random_Word = RandomWord()\n",
    "\n",
    "# Function to generate a random grid of nouns\n",
    "def create_unique_random_grid(nouns, size):\n",
    "    random_nouns = random.sample(nouns, size * size)\n",
    "    return [random_nouns[i * size:(i + 1) * size] for i in range(size)]\n",
    "\n",
    "# Function to generate all start-end combinations for a given grid\n",
    "def generate_start_end_permutations(size):\n",
    "    combinations = []\n",
    "    for start_x in range(size):\n",
    "        for start_y in range(size):\n",
    "            for end_x in range(size):\n",
    "                for end_y in range(size):\n",
    "                    if (start_x, start_y) != (end_x, end_y):  # Exclude combinations where start == end\n",
    "                        combinations.append(((start_x, start_y), (end_x, end_y)))\n",
    "    return combinations\n",
    "\n",
    "# Function to generate all possible optimal paths for given start-end combinations\n",
    "def generate_path_permutations(combinations):\n",
    "    paths = []\n",
    "    for start, end in combinations:\n",
    "        horizontal_steps = abs(end[1] - start[1])  # Difference in columns\n",
    "        vertical_steps = abs(end[0] - start[0])    # Difference in rows\n",
    "        steps = ['H'] * horizontal_steps + ['V'] * vertical_steps\n",
    "\n",
    "        unique_permutations = set(permutations(steps))\n",
    "\n",
    "        for perm in unique_permutations:\n",
    "            path = [start]\n",
    "            current_pos = list(start)\n",
    "            for step in perm:\n",
    "                if step == 'H':\n",
    "                    current_pos[1] += 1 if end[1] > start[1] else -1\n",
    "                else:  # 'V'\n",
    "                    current_pos[0] += 1 if end[0] > start[0] else -1\n",
    "                path.append(tuple(current_pos))\n",
    "            # Append each path to the paths list\n",
    "            paths.append({'start': start, 'end': end, 'path': path})\n",
    "\n",
    "    return paths\n",
    "\n",
    "# Function to generate nouns\n",
    "def generate_nouns(size):\n",
    "    Random_Word = RandomWord()\n",
    "    nouns = set()\n",
    "    while len(nouns) < size * size:\n",
    "        # Fetching a random noun and replacing spaces with underscores\n",
    "        word = Random_Word.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\")\n",
    "        if word:  # Ensure that 'None' isn't added to the set if no word is returned\n",
    "            nouns.add(word)\n",
    "    return list(nouns)\n",
    "\n",
    "def shuffle_stimuli(stimuli):\n",
    "    random.shuffle(stimuli)\n",
    "    return stimuli\n",
    "\n",
    "def get_direction(prev_coord, coord):\n",
    "    if coord[0] == prev_coord[0]:\n",
    "        if coord[1] > prev_coord[1]:\n",
    "            return \"R\"\n",
    "        else:\n",
    "            return \"L\"\n",
    "    else:\n",
    "        if coord[0] > prev_coord[0]:\n",
    "            return \"D\"\n",
    "        else:\n",
    "            return \"U\"\n",
    "\n",
    "def generate_all_suboptimal_paths(size):\n",
    "\n",
    "    def is_valid_move(start, end):\n",
    "        \"\"\"Check if the move from start to end is valid (adjacent cells).\"\"\"\n",
    "        return abs(start[0] - end[0]) + abs(start[1] - end[1]) == 1\n",
    "\n",
    "    def is_suboptimal(path, start, end):\n",
    "        \"\"\"Check if the path is suboptimal (longer than the Manhattan distance).\"\"\"\n",
    "        optimal_length = abs(end[0] - start[0]) + abs(end[1] - start[1])\n",
    "        return len(path) > optimal_length + 1  # Must be longer than the optimal path\n",
    "\n",
    "    def generate_all_possible_paths(size):\n",
    "        \"\"\"Generate all possible valid paths for a given grid size.\"\"\"\n",
    "        coords = [(x, y) for x in range(size) for y in range(size)]\n",
    "        all_paths = []\n",
    "        for start in coords:\n",
    "            for end in coords:\n",
    "                if start != end:\n",
    "                    queue = [[start]]\n",
    "                    while queue:\n",
    "                        path = queue.pop(0)\n",
    "                        current_pos = path[-1]\n",
    "                        if current_pos == end:\n",
    "                            if is_suboptimal(path, start, end):\n",
    "                                all_paths.append(path)\n",
    "                        else:\n",
    "                            for move in [(0, 1), (1, 0), (0, -1), (-1, 0)]:  # Right, Down, Left, Up\n",
    "                                next_pos = (current_pos[0] + move[0], current_pos[1] + move[1])\n",
    "                                if (0 <= next_pos[0] < size and 0 <= next_pos[1] < size and\n",
    "                                    next_pos not in path and is_valid_move(current_pos, next_pos)):\n",
    "                                    queue.append(path + [next_pos])\n",
    "        return all_paths\n",
    "\n",
    "    \"\"\"Generate all suboptimal paths for a given grid size.\"\"\"\n",
    "    suboptimal_paths = []\n",
    "    all_possible_paths = generate_all_possible_paths(size)\n",
    "    for path in all_possible_paths:\n",
    "        suboptimal_paths.append({'start': path[0], 'end': path[-1], 'path': path})\n",
    "    return suboptimal_paths\n",
    "\n",
    "def get_movement_options(coord, grid_size, prev_coord):\n",
    "    options = [\"U\", \"D\", \"L\", \"R\"]\n",
    "    moves = {\n",
    "        \"U\": (coord[0] - 1, coord[1]),\n",
    "        \"D\": (coord[0] + 1, coord[1]),\n",
    "        \"L\": (coord[0], coord[1] - 1),\n",
    "        \"R\": (coord[0], coord[1] + 1)\n",
    "    }\n",
    "    valid_moves = []\n",
    "    for option in options:\n",
    "        move = moves[option]\n",
    "        if 0 <= move[0] < grid_size and 0 <= move[1] < grid_size and move != prev_coord:\n",
    "            valid_moves.append(option)\n",
    "        else:\n",
    "            valid_moves.append(\"NA\")\n",
    "    return f\"[{' '.join(valid_moves)}]\"\n",
    "\n",
    "def generate_shortest_path_string(grid, path_coords, probability):\n",
    "    if not path_coords:\n",
    "        return \"\"\n",
    "\n",
    "    size = len(grid)\n",
    "    start, end = path_coords[0], path_coords[-1]\n",
    "    path_string = f\"MODE: Shortest, START: {grid[start[0]][start[1]]}, END: {grid[end[0]][end[1]]}, PATH: \"\n",
    "    prev_coord = None\n",
    "    first_step = True\n",
    "\n",
    "    for i, coord in enumerate(path_coords):\n",
    "        if coord == start:\n",
    "            path_string += grid[start[0]][start[1]]\n",
    "        else:\n",
    "            direction = get_direction(prev_coord, coord)\n",
    "            if first_step:\n",
    "                movement_options = get_movement_options(prev_coord, size, path_coords[i - 2] if i > 1 else None)\n",
    "                path_string += f\" {movement_options} {direction}\"\n",
    "                first_step = False\n",
    "            else:\n",
    "                path_string += f\" {direction}\"\n",
    "\n",
    "            if coord == end:\n",
    "                path_string += f\" {grid[coord[0]][coord[1]]}\"\n",
    "            else:\n",
    "                if random.random() < probability:\n",
    "                    path_string += f\" {grid[coord[0]][coord[1]]}\"\n",
    "                else:\n",
    "                    path_string += \" FORGOT\"\n",
    "\n",
    "        prev_coord = coord\n",
    "\n",
    "    return path_string\n",
    "\n",
    "def generate_foraging_path_string(grid, path_coords, probability):\n",
    "    if not path_coords:\n",
    "        return \"\"\n",
    "\n",
    "    size = len(grid)\n",
    "    start, end = path_coords[0], path_coords[-1]\n",
    "    path_string = f\"MODE: Foraging, START: {grid[start[0]][start[1]]}, END: {grid[end[0]][end[1]]}, PATH: \"\n",
    "    prev_coord = None\n",
    "    first_step = True\n",
    "\n",
    "    for i, coord in enumerate(path_coords):\n",
    "        if coord == start:\n",
    "            path_string += grid[start[0]][start[1]]\n",
    "        else:\n",
    "            direction = get_direction(prev_coord, coord)\n",
    "            if first_step:\n",
    "                movement_options = get_movement_options(prev_coord, size, path_coords[i - 2] if i > 1 else None)\n",
    "                path_string += f\" {movement_options} {direction}\"\n",
    "                first_step = False\n",
    "            else:\n",
    "                path_string += f\" {direction}\"\n",
    "\n",
    "            if coord == end:\n",
    "                path_string += f\" {grid[coord[0]][coord[1]]}\"\n",
    "            else:\n",
    "                if random.random() < probability:\n",
    "                    path_string += f\" {grid[coord[0]][coord[1]]}\"\n",
    "                else:\n",
    "                    path_string += \" FORGOT\"\n",
    "\n",
    "        prev_coord = coord\n",
    "\n",
    "    return path_string\n",
    "\n",
    "size = 4  # Grid size\n",
    "shortest_paths_iterations = 1 # How many times each optimal path is included in the training data\n",
    "num_suboptimal = 744 # How many suboptimal paths to be randomly selected for a single grid environment\n",
    "probability = 1 # The probability of forgetting intermediate locations in a given path\n",
    "\n",
    "training_strs = []\n",
    "for i in range(3000): # Number of grid environments in training data\n",
    "    nouns_list = generate_nouns(size)\n",
    "    grid = create_unique_random_grid(nouns_list, size)\n",
    "    start_end_combinations = generate_start_end_permutations(size)\n",
    "\n",
    "    shortest_paths = generate_path_permutations(start_end_combinations)\n",
    "    suboptimal_paths = generate_all_suboptimal_paths(size)\n",
    "\n",
    "    generated_path_strings = []\n",
    "\n",
    "    # Add all shortest paths for a specified number of times (shortest_paths_iterations) to the list of generated path strings\n",
    "    for _ in range(shortest_paths_iterations):\n",
    "        for path in shortest_paths:\n",
    "            generated_path_strings.append(generate_shortest_path_string(grid, path['path'], probability))\n",
    "\n",
    "    # From all possible subtoptimal paths, randomly select a specified number and add to the list\n",
    "    selected_paths = random.sample(suboptimal_paths, num_suboptimal)\n",
    "    for path in selected_paths:\n",
    "        generated_path_strings.append(generate_foraging_path_string(grid, path['path'], probability))\n",
    "\n",
    "    # Shuffle the list of generated path strings\n",
    "    generated_path_strings = shuffle_stimuli(generated_path_strings)\n",
    "\n",
    "    # Append the generated path strings to the training strings list\n",
    "    training_strs += generated_path_strings\n",
    "\n",
    "    # Print the iteration number\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i} completed.\")\n",
    "\n",
    "testing_strs = []\n",
    "for i in range(30): # Number of grid environments in testing data\n",
    "    nouns_list = generate_nouns(size)\n",
    "    grid = create_unique_random_grid(nouns_list, size)\n",
    "    start_end_combinations = generate_start_end_permutations(size)\n",
    "\n",
    "    shortest_paths = generate_path_permutations(start_end_combinations)\n",
    "    suboptimal_paths = generate_all_suboptimal_paths(size)\n",
    "\n",
    "    generated_path_strings = []\n",
    "\n",
    "    # Add all shortest paths for a specified number of times (shortest_paths_iterations) to the list of generated path strings\n",
    "    for _ in range(shortest_paths_iterations):\n",
    "        for path in shortest_paths:\n",
    "            generated_path_strings.append(generate_shortest_path_string(grid, path['path'], probability))\n",
    "\n",
    "    # From all possible subtoptimal paths, randomly select a specified number and add to the list\n",
    "    selected_paths = random.sample(suboptimal_paths, num_suboptimal)\n",
    "    for path in selected_paths:\n",
    "        generated_path_strings.append(generate_foraging_path_string(grid, path['path'], probability))\n",
    "\n",
    "    # Shuffle the list of generated path strings\n",
    "    generated_path_strings = shuffle_stimuli(generated_path_strings)\n",
    "\n",
    "    # Append the generated path strings to the testing strings list\n",
    "    testing_strs += generated_path_strings\n",
    "\n",
    "# Print the total number of training and testing path strings\n",
    "print(f\"\\n{len(training_strs)} paths generated for pre-training.\")\n",
    "print(f\"{len(testing_strs)} paths generated for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e5c52-5e6a-4769-983b-23a1117d1c08",
   "metadata": {
    "id": "f61e5c52-5e6a-4769-983b-23a1117d1c08"
   },
   "source": [
    "Write training and testing data into .txt files, and count number of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9039427a-4609-4b49-b39c-ce4cbedccaf9",
   "metadata": {
    "id": "9039427a-4609-4b49-b39c-ce4cbedccaf9",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'spatial_model': Directory not empty\n",
      "mkdir: cannot create directory ‘spatial_model’: File exists\n"
     ]
    }
   ],
   "source": [
    "!rm -rf spatial_model\n",
    "!mkdir spatial_model\n",
    "\n",
    "text_file = open(\"spatial_model/train.txt\", \"w\")\n",
    "n = text_file.write('\\n'.join(training_strs))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"spatial_model/test.txt\", \"w\")\n",
    "n = text_file.write('\\n'.join(testing_strs))\n",
    "text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eededfef",
   "metadata": {},
   "source": [
    "### Train/Fine-Tune GPT-2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc5469",
   "metadata": {
    "id": "61dc5469"
   },
   "source": [
    "The function below runs a script to fine-tune a gpt-2 model on the arbitrary stimuli.\n",
    "\n",
    "The name_or_path argument is which model to fine-tune from. In the pre-training stage, this will be set to 'gpt2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91455446",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7731,
     "status": "ok",
     "timestamp": 1718189460467,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "91455446",
    "outputId": "8a442527-a130-42c9-cb8d-c5bdb2e0a59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Check CUDA, MPS, and CPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available. Using CUDA.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"MPS available. Using MPS.\")\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA and MPS not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "XMzmuqSrZJOj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1718190817599,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "XMzmuqSrZJOj",
    "outputId": "d9f11c2e-0d94-4b63-ab81-6fca970280ba"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953f3e59",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1718189460467,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "953f3e59"
   },
   "outputs": [],
   "source": [
    "# def train_model_script(name_or_path='spatial_model',\n",
    "#                        num_epochs=1,\n",
    "#                        output_dir='./models',\n",
    "#                        save_strategy=\"steps\",\n",
    "#                        save_steps=111600,  # ≈ every 10% of training\n",
    "#                        lr=5e-05,\n",
    "#                        train_batch_size=32,\n",
    "#                        eval_batch_size=32,\n",
    "#                        block_size=1024):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     ! python ./run_clm.py \\\n",
    "#         --model_name_or_path {name_or_path} \\\n",
    "#         --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "#         --validation_file {os.path.join(output_dir, 'test.txt')} \\\n",
    "#         --per_device_train_batch_size {train_batch_size} \\\n",
    "#         --per_device_eval_batch_size {eval_batch_size} \\\n",
    "#         --do_train \\\n",
    "#         --do_eval \\\n",
    "#         --output_dir {output_dir} \\\n",
    "#         --overwrite_output_dir \\\n",
    "#         --num_train_epochs {num_epochs} \\\n",
    "#         --save_strategy steps \\\n",
    "#         --save_steps {save_steps} \\\n",
    "#         --learning_rate {lr} \\\n",
    "#         --block_size {block_size}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_script(name_or_path='spatial_model',\n",
    "                       num_epochs=1,\n",
    "                       output_dir='./spatial_model',\n",
    "                       save_strategy=\"steps\",\n",
    "                       save_steps=111600,\n",
    "                       lr=5e-5,\n",
    "                       train_batch_size=32,\n",
    "                       eval_batch_size=32,\n",
    "                       block_size=1024):\n",
    "    import torch, gc, os\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Define model and tokenizer names explicitly\n",
    "    model_type = \"gpt2\"\n",
    "    tokenizer_name = \"gpt2\"\n",
    "\n",
    "    # Assemble the training command\n",
    "    os.system(f\"\"\"\n",
    "    python ./run_clm.py \\\n",
    "        --model_type {model_type} \\\n",
    "        --tokenizer_name {tokenizer_name} \\\n",
    "        --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --validation_file {os.path.join(output_dir, 'test.txt')} \\\n",
    "        --per_device_train_batch_size {train_batch_size} \\\n",
    "        --per_device_eval_batch_size {eval_batch_size} \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --evaluation_strategy \"steps\" \\\n",
    "        --eval_steps {save_steps} \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy {save_strategy} \\\n",
    "        --save_steps {save_steps} \\\n",
    "        --learning_rate {lr} \\\n",
    "        --block_size {block_size}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f16b977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /cs/student/msc/aibh/2024/cbaumgar/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "loading file merges.txt from cache at /cs/student/msc/aibh/2024/cbaumgar/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /cs/student/msc/aibh/2024/cbaumgar/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /cs/student/msc/aibh/2024/cbaumgar/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /cs/student/msc/aibh/2024/cbaumgar/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 4464000\n",
      "Average tokens per line (estimated): 37.67\n",
      "Estimated total tokens: 168,158,880\n",
      "Approx. training steps per epoch: 41,054\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "with open(\"spatial_model/train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"Total lines: {len(lines)}\")\n",
    "\n",
    "sample = lines[:100]\n",
    "token_counts = [len(tokenizer.encode(line.strip())) for line in sample]\n",
    "avg_tokens_per_line = sum(token_counts) / len(token_counts)\n",
    "\n",
    "print(f\"Average tokens per line (estimated): {avg_tokens_per_line:.2f}\")\n",
    "\n",
    "total_estimated_tokens = len(lines) * avg_tokens_per_line\n",
    "print(f\"Estimated total tokens: {int(total_estimated_tokens):,}\")\n",
    "block_size = 1024\n",
    "train_batch_size = 4\n",
    "\n",
    "num_blocks = int(total_estimated_tokens) // block_size\n",
    "num_steps = num_blocks // train_batch_size\n",
    "\n",
    "print(f\"Approx. training steps per epoch: {num_steps:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307af71c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61186823,
     "status": "ok",
     "timestamp": 1718270406876,
     "user": {
      "displayName": "Chin Hoi Wong",
      "userId": "07679049059743907704"
     },
     "user_tz": -60
    },
    "id": "307af71c",
    "outputId": "cd07d104-7052-4cbc-ec6d-3066ed04151d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:56:09 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "06/09/2025 15:56:09 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./spatial_model/runs/Jun09_15-56-08_skate-l.cs.ucl.ac.uk,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./spatial_model,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./spatial_model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=4471,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f886da7084900083\n",
      "Loading Dataset Infos from /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/datasets/packaged_modules/text\n",
      "Generating dataset text (/cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99)\n",
      "Downloading and preparing dataset text/default to /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99...\n",
      "Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "Generating train split\n",
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:56:09 - INFO - datasets.builder - Using custom data configuration default-f886da7084900083\n",
      "06/09/2025 15:56:09 - INFO - datasets.info - Loading Dataset Infos from /cs/student/projects1/aibh/2024/cbaumgar/.venv/lib64/python3.9/site-packages/datasets/packaged_modules/text\n",
      "06/09/2025 15:56:09 - INFO - datasets.builder - Generating dataset text (/cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99)\n",
      "06/09/2025 15:56:09 - INFO - datasets.builder - Downloading and preparing dataset text/default to /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99...\n",
      "06/09/2025 15:56:09 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
      "06/09/2025 15:56:09 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
      "06/09/2025 15:56:09 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4464000 examples [00:05, 772158.83 examples/s]\n",
      "Generating validation split\n",
      "Generating validation split: 44640 examples [00:00, 506874.14 examples/s]\n",
      "Unable to verify splits sizes.\n",
      "Dataset text downloaded and prepared to /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:56:15 - INFO - datasets.builder - Generating validation split\n",
      "06/09/2025 15:56:15 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
      "06/09/2025 15:56:15 - INFO - datasets.builder - Dataset text downloaded and prepared to /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99. Subsequent calls will reuse this data.\n",
      "06/09/2025 15:56:21 - WARNING - __main__ - You are instantiating a new config instance from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:714] 2025-06-09 15:56:22,283 >> loading configuration file config.json from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:786] 2025-06-09 15:56:22,285 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,482 >> loading file vocab.json from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,482 >> loading file merges.txt from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,482 >> loading file tokenizer.json from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,482 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,482 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,483 >> loading file tokenizer_config.json from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2023] 2025-06-09 15:56:22,483 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|configuration_utils.py:714] 2025-06-09 15:56:22,484 >> loading configuration file config.json from cache at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "[INFO|configuration_utils.py:786] 2025-06-09 15:56:22,486 >> Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:1122] 2025-06-09 15:56:22,668 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:56:24 - INFO - __main__ - Training new model from scratch - Total size=118.68M params\n",
      "06/09/2025 15:56:24 - INFO - datasets.arrow_dataset - Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-d82f793a601bf196.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   0%|          | 0/4464000 [00:00<?, ? examples/s]Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-d82f793a601bf196.arrow\n",
      "Running tokenizer on dataset: 100%|██████████| 4464000/4464000 [03:00<00:00, 24714.56 examples/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/44640 [00:00<?, ? examples/s]Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-c8ed3a4f52837698.arrow\n",
      "Running tokenizer on dataset:   9%|▉         | 4000/44640 [00:00<00:01, 28803.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:59:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-c8ed3a4f52837698.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 44640/44640 [00:01<00:00, 24654.15 examples/s]\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/4464000 [00:00<?, ? examples/s]Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-a0cc1ce08c3abe92.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 15:59:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-a0cc1ce08c3abe92.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping texts in chunks of 1024: 100%|██████████| 4464000/4464000 [04:07<00:00, 18071.80 examples/s]\n",
      "Grouping texts in chunks of 1024:   0%|          | 0/44640 [00:00<?, ? examples/s]Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-4f3b5b319837c906.arrow\n",
      "Grouping texts in chunks of 1024:   7%|▋         | 3000/44640 [00:00<00:02, 20027.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09/2025 16:03:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /cs/student/projects1/aibh/2024/cbaumgar/hf_cache/datasets/text/default-f886da7084900083/0.0.0/37eaf37ac90527a7fd768c94b312ee84f8815c9b7ac00acf81c1c364e8392f99/cache-4f3b5b319837c906.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping texts in chunks of 1024: 100%|██████████| 44640/44640 [00:02<00:00, 19267.80 examples/s]\n",
      "/cs/student/projects1/aibh/2024/cbaumgar/MSC_THESIS/./run_clm.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "[INFO|trainer.py:2409] 2025-06-09 16:03:38,585 >> ***** Running training *****\n",
      "[INFO|trainer.py:2410] 2025-06-09 16:03:38,585 >>   Num examples = 178,634\n",
      "[INFO|trainer.py:2411] 2025-06-09 16:03:38,585 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2412] 2025-06-09 16:03:38,585 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2415] 2025-06-09 16:03:38,585 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2416] 2025-06-09 16:03:38,585 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2417] 2025-06-09 16:03:38,585 >>   Total optimization steps = 44,659\n",
      "[INFO|trainer.py:2418] 2025-06-09 16:03:38,586 >>   Number of trainable parameters = 124,439,808\n",
      "  0%|          | 0/44659 [00:00<?, ?it/s][WARNING|logging.py:328] 2025-06-09 16:03:38,904 >> `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "  1%|          | 500/44659 [02:15<3:43:10,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0321, 'grad_norm': 1.9362878799438477, 'learning_rate': 4.944132201795831e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1000/44659 [04:42<3:22:48,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2082, 'grad_norm': 1.9226945638656616, 'learning_rate': 4.888152444076222e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1500/44659 [07:03<3:26:41,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8651, 'grad_norm': 2.0092546939849854, 'learning_rate': 4.8321726863566136e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2000/44659 [09:18<3:05:14,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5853, 'grad_norm': 2.1881282329559326, 'learning_rate': 4.776192928637005e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2500/44659 [11:31<3:01:25,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3633, 'grad_norm': 2.172527313232422, 'learning_rate': 4.720213170917396e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3000/44659 [13:41<2:55:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1822, 'grad_norm': 2.296302556991577, 'learning_rate': 4.6642334131977876e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3500/44659 [15:52<3:05:32,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0326, 'grad_norm': 2.2892661094665527, 'learning_rate': 4.608253655478179e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4000/44659 [18:01<2:47:29,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9087, 'grad_norm': 2.148977041244507, 'learning_rate': 4.55227389775857e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4471/44659 [20:01<2:46:19,  4.03it/s][INFO|trainer.py:3993] 2025-06-09 16:23:39,861 >> Saving model checkpoint to ./spatial_model/checkpoint-4471\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 16:23:39,872 >> Configuration saved in ./spatial_model/checkpoint-4471/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 16:23:39,874 >> Configuration saved in ./spatial_model/checkpoint-4471/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 16:23:44,421 >> Model weights saved in ./spatial_model/checkpoint-4471/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 16:23:44,456 >> tokenizer config file saved in ./spatial_model/checkpoint-4471/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 16:23:44,473 >> Special tokens file saved in ./spatial_model/checkpoint-4471/special_tokens_map.json\n",
      "[WARNING|logging.py:328] 2025-06-09 16:23:53,480 >> `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      " 10%|█         | 4500/44659 [20:46<2:51:01,  3.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.765, 'grad_norm': 2.1517210006713867, 'learning_rate': 4.4962941400389616e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5000/44659 [22:54<2:41:21,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6226, 'grad_norm': 1.9677956104278564, 'learning_rate': 4.440314382319353e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5500/44659 [25:03<3:18:18,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4895, 'grad_norm': 2.024117946624756, 'learning_rate': 4.384334624599745e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6000/44659 [27:11<2:39:48,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3373, 'grad_norm': 2.2361490726470947, 'learning_rate': 4.328354866880136e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6500/44659 [29:17<2:32:25,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1218, 'grad_norm': 3.7867226600646973, 'learning_rate': 4.272375109160528e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7000/44659 [31:22<2:30:05,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9689, 'grad_norm': 3.6832528114318848, 'learning_rate': 4.216395351440919e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7500/44659 [33:26<2:38:28,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8729, 'grad_norm': 2.906255006790161, 'learning_rate': 4.160415593721311e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 8000/44659 [35:30<2:50:26,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8033, 'grad_norm': 3.0774054527282715, 'learning_rate': 4.1044358360017024e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8500/44659 [37:33<2:25:09,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.755, 'grad_norm': 2.636895179748535, 'learning_rate': 4.048456078282094e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8942/44659 [39:21<2:23:23,  4.15it/s][INFO|trainer.py:3993] 2025-06-09 16:43:00,265 >> Saving model checkpoint to ./spatial_model/checkpoint-8942\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 16:43:00,282 >> Configuration saved in ./spatial_model/checkpoint-8942/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 16:43:00,285 >> Configuration saved in ./spatial_model/checkpoint-8942/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 16:43:04,800 >> Model weights saved in ./spatial_model/checkpoint-8942/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 16:43:04,803 >> tokenizer config file saved in ./spatial_model/checkpoint-8942/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 16:43:04,813 >> Special tokens file saved in ./spatial_model/checkpoint-8942/special_tokens_map.json\n",
      " 20%|██        | 9000/44659 [40:12<2:22:36,  4.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7141, 'grad_norm': 2.5869879722595215, 'learning_rate': 3.992476320562485e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9500/44659 [42:13<2:19:51,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6889, 'grad_norm': 2.037231206893921, 'learning_rate': 3.9364965628428764e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10000/44659 [44:15<2:18:03,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6619, 'grad_norm': 2.051349401473999, 'learning_rate': 3.880516805123268e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 10500/44659 [46:16<2:15:48,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.641, 'grad_norm': 2.0277466773986816, 'learning_rate': 3.824537047403659e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 11000/44659 [48:17<2:14:03,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6231, 'grad_norm': 1.5715440511703491, 'learning_rate': 3.7685572896840504e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11500/44659 [50:17<2:11:27,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6084, 'grad_norm': 1.964974045753479, 'learning_rate': 3.712577531964442e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 12000/44659 [52:18<2:11:31,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5951, 'grad_norm': 1.5296838283538818, 'learning_rate': 3.656597774244833e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 12500/44659 [54:18<2:10:02,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5858, 'grad_norm': 1.8591394424438477, 'learning_rate': 3.6006180165252245e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 13000/44659 [56:18<2:05:42,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5755, 'grad_norm': 1.8561731576919556, 'learning_rate': 3.544638258805616e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 13413/44659 [57:57<2:03:51,  4.20it/s][INFO|trainer.py:3993] 2025-06-09 17:01:36,492 >> Saving model checkpoint to ./spatial_model/checkpoint-13413\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 17:01:36,495 >> Configuration saved in ./spatial_model/checkpoint-13413/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 17:01:36,498 >> Configuration saved in ./spatial_model/checkpoint-13413/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 17:01:41,007 >> Model weights saved in ./spatial_model/checkpoint-13413/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 17:01:41,010 >> tokenizer config file saved in ./spatial_model/checkpoint-13413/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 17:01:41,013 >> Special tokens file saved in ./spatial_model/checkpoint-13413/special_tokens_map.json\n",
      " 30%|███       | 13500/44659 [58:55<2:03:00,  4.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5679, 'grad_norm': 1.8266031742095947, 'learning_rate': 3.488658501086007e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 14000/44659 [1:00:55<2:01:29,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5545, 'grad_norm': 1.5658609867095947, 'learning_rate': 3.4326787433663985e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 14500/44659 [1:02:55<2:02:39,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5473, 'grad_norm': 1.5117014646530151, 'learning_rate': 3.37669898564679e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 15000/44659 [1:04:55<1:58:10,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5386, 'grad_norm': 1.7270382642745972, 'learning_rate': 3.320719227927181e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 15500/44659 [1:06:54<1:56:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5357, 'grad_norm': 1.3009310960769653, 'learning_rate': 3.2647394702075725e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 16000/44659 [1:08:54<1:53:37,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5257, 'grad_norm': 1.588313102722168, 'learning_rate': 3.2087597124879646e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 16500/44659 [1:10:53<1:51:31,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5154, 'grad_norm': 1.8099697828292847, 'learning_rate': 3.152779954768356e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 17000/44659 [1:12:53<1:50:10,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5069, 'grad_norm': 1.438483476638794, 'learning_rate': 3.096800197048747e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 17500/44659 [1:14:52<1:47:26,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4998, 'grad_norm': 1.643287181854248, 'learning_rate': 3.040820439329139e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17884/44659 [1:16:24<1:46:25,  4.19it/s][INFO|trainer.py:3993] 2025-06-09 17:20:03,079 >> Saving model checkpoint to ./spatial_model/checkpoint-17884\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 17:20:03,103 >> Configuration saved in ./spatial_model/checkpoint-17884/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 17:20:03,106 >> Configuration saved in ./spatial_model/checkpoint-17884/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 17:20:08,057 >> Model weights saved in ./spatial_model/checkpoint-17884/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 17:20:08,073 >> tokenizer config file saved in ./spatial_model/checkpoint-17884/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 17:20:08,081 >> Special tokens file saved in ./spatial_model/checkpoint-17884/special_tokens_map.json\n",
      " 40%|████      | 18000/44659 [1:17:31<1:45:13,  4.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4899, 'grad_norm': 1.4446663856506348, 'learning_rate': 2.9848406816095303e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 18500/44659 [1:19:30<1:43:35,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4809, 'grad_norm': 1.3400321006774902, 'learning_rate': 2.9288609238899216e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 19000/44659 [1:21:29<1:41:41,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4662, 'grad_norm': 1.4021421670913696, 'learning_rate': 2.872881166170313e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 19500/44659 [1:23:29<1:40:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4565, 'grad_norm': 1.1603765487670898, 'learning_rate': 2.8169014084507046e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 20000/44659 [1:25:28<1:37:53,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4509, 'grad_norm': 1.0964698791503906, 'learning_rate': 2.760921650731096e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 20500/44659 [1:27:27<1:35:40,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4455, 'grad_norm': 1.6083961725234985, 'learning_rate': 2.7049418930114873e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 21000/44659 [1:29:26<1:33:48,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4389, 'grad_norm': 1.17170250415802, 'learning_rate': 2.6489621352918787e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 21500/44659 [1:31:25<1:31:43,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4336, 'grad_norm': 1.459490180015564, 'learning_rate': 2.59298237757227e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 22000/44659 [1:33:24<1:30:24,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4317, 'grad_norm': 1.1638693809509277, 'learning_rate': 2.5370026198526614e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 22355/44659 [1:34:49<1:28:20,  4.21it/s][INFO|trainer.py:3993] 2025-06-09 17:38:28,203 >> Saving model checkpoint to ./spatial_model/checkpoint-22355\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 17:38:28,241 >> Configuration saved in ./spatial_model/checkpoint-22355/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 17:38:28,253 >> Configuration saved in ./spatial_model/checkpoint-22355/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 17:38:33,270 >> Model weights saved in ./spatial_model/checkpoint-22355/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 17:38:33,273 >> tokenizer config file saved in ./spatial_model/checkpoint-22355/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 17:38:33,274 >> Special tokens file saved in ./spatial_model/checkpoint-22355/special_tokens_map.json\n",
      " 50%|█████     | 22500/44659 [1:36:05<1:27:29,  4.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4259, 'grad_norm': 1.4108525514602661, 'learning_rate': 2.4810228621330527e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 23000/44659 [1:38:04<1:26:02,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4199, 'grad_norm': 1.9027652740478516, 'learning_rate': 2.425043104413444e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 23500/44659 [1:40:04<1:23:58,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4179, 'grad_norm': 1.9737995862960815, 'learning_rate': 2.3690633466938354e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 24000/44659 [1:42:04<1:21:49,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4144, 'grad_norm': 1.2620662450790405, 'learning_rate': 2.313083588974227e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 24500/44659 [1:44:03<1:19:54,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4085, 'grad_norm': 2.250483751296997, 'learning_rate': 2.2571038312546184e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 25000/44659 [1:46:02<1:17:48,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4078, 'grad_norm': 1.0301012992858887, 'learning_rate': 2.2011240735350098e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 25500/44659 [1:48:01<1:15:55,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4035, 'grad_norm': 0.8855036497116089, 'learning_rate': 2.1451443158154015e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 26000/44659 [1:50:00<1:13:54,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4009, 'grad_norm': 1.145443081855774, 'learning_rate': 2.0891645580957928e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 26500/44659 [1:51:59<1:11:54,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3966, 'grad_norm': 0.9544210433959961, 'learning_rate': 2.033184800376184e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 26826/44659 [1:53:17<1:10:38,  4.21it/s][INFO|trainer.py:3993] 2025-06-09 17:56:56,280 >> Saving model checkpoint to ./spatial_model/checkpoint-26826\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 17:56:56,285 >> Configuration saved in ./spatial_model/checkpoint-26826/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 17:56:56,298 >> Configuration saved in ./spatial_model/checkpoint-26826/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 17:57:00,838 >> Model weights saved in ./spatial_model/checkpoint-26826/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 17:57:00,850 >> tokenizer config file saved in ./spatial_model/checkpoint-26826/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 17:57:00,852 >> Special tokens file saved in ./spatial_model/checkpoint-26826/special_tokens_map.json\n",
      " 60%|██████    | 27000/44659 [1:54:35<1:09:51,  4.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3947, 'grad_norm': 0.9752354025840759, 'learning_rate': 1.9772050426565755e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 27500/44659 [1:56:38<1:08:28,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3923, 'grad_norm': 1.1437724828720093, 'learning_rate': 1.9212252849369668e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 28000/44659 [1:58:37<1:06:29,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3914, 'grad_norm': 1.8733967542648315, 'learning_rate': 1.8652455272173582e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 28500/44659 [2:00:36<1:04:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3902, 'grad_norm': 0.9778635501861572, 'learning_rate': 1.8092657694977495e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 29000/44659 [2:02:36<1:02:24,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3848, 'grad_norm': 0.9585773944854736, 'learning_rate': 1.7532860117781412e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 29500/44659 [2:04:35<1:00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3833, 'grad_norm': 0.7850265502929688, 'learning_rate': 1.6973062540585325e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 30000/44659 [2:06:34<58:08,  4.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3807, 'grad_norm': 1.3555561304092407, 'learning_rate': 1.641326496338924e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 30500/44659 [2:08:33<56:07,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3798, 'grad_norm': 1.1664217710494995, 'learning_rate': 1.5853467386193152e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 31000/44659 [2:10:32<54:10,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3772, 'grad_norm': 0.9546481370925903, 'learning_rate': 1.529366980899707e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 31297/44659 [2:11:43<53:19,  4.18it/s][INFO|trainer.py:3993] 2025-06-09 18:15:21,787 >> Saving model checkpoint to ./spatial_model/checkpoint-31297\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 18:15:21,938 >> Configuration saved in ./spatial_model/checkpoint-31297/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 18:15:22,042 >> Configuration saved in ./spatial_model/checkpoint-31297/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 18:15:26,621 >> Model weights saved in ./spatial_model/checkpoint-31297/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 18:15:26,622 >> tokenizer config file saved in ./spatial_model/checkpoint-31297/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 18:15:26,624 >> Special tokens file saved in ./spatial_model/checkpoint-31297/special_tokens_map.json\n",
      " 71%|███████   | 31500/44659 [2:13:11<52:10,  4.20it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3738, 'grad_norm': 1.120937466621399, 'learning_rate': 1.4733872231800983e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 32000/44659 [2:15:10<50:26,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3745, 'grad_norm': 2.5947728157043457, 'learning_rate': 1.4174074654604896e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 32500/44659 [2:17:10<48:38,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3715, 'grad_norm': 1.1507192850112915, 'learning_rate': 1.361427707740881e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 33000/44659 [2:19:12<47:13,  4.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3691, 'grad_norm': 1.0835250616073608, 'learning_rate': 1.3054479500212725e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 33500/44659 [2:21:12<45:18,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3686, 'grad_norm': 0.9590710997581482, 'learning_rate': 1.2494681923016638e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 34000/44659 [2:23:13<42:19,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3679, 'grad_norm': 0.8660829663276672, 'learning_rate': 1.1934884345820551e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 34500/44659 [2:25:13<40:57,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3653, 'grad_norm': 0.8478999137878418, 'learning_rate': 1.1375086768624465e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 35000/44659 [2:27:14<38:48,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.363, 'grad_norm': 0.9094803333282471, 'learning_rate': 1.081528919142838e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 35500/44659 [2:29:14<36:22,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3617, 'grad_norm': 0.9149898290634155, 'learning_rate': 1.0255491614232295e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 35768/44659 [2:30:19<35:17,  4.20it/s][INFO|trainer.py:3993] 2025-06-09 18:33:58,151 >> Saving model checkpoint to ./spatial_model/checkpoint-35768\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 18:33:58,155 >> Configuration saved in ./spatial_model/checkpoint-35768/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 18:33:58,173 >> Configuration saved in ./spatial_model/checkpoint-35768/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 18:34:02,855 >> Model weights saved in ./spatial_model/checkpoint-35768/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 18:34:02,869 >> tokenizer config file saved in ./spatial_model/checkpoint-35768/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 18:34:02,871 >> Special tokens file saved in ./spatial_model/checkpoint-35768/special_tokens_map.json\n",
      " 81%|████████  | 36000/44659 [2:31:53<34:14,  4.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3625, 'grad_norm': 0.9287818074226379, 'learning_rate': 9.695694037036209e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 36500/44659 [2:33:54<32:23,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3591, 'grad_norm': 0.9804643392562866, 'learning_rate': 9.135896459840122e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 37000/44659 [2:35:53<30:29,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3611, 'grad_norm': 0.9759376049041748, 'learning_rate': 8.576098882644035e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 37500/44659 [2:37:54<28:48,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3575, 'grad_norm': 0.9877870678901672, 'learning_rate': 8.01630130544795e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 38000/44659 [2:39:54<26:25,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3565, 'grad_norm': 0.8170363306999207, 'learning_rate': 7.456503728251865e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 38500/44659 [2:41:54<24:27,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3574, 'grad_norm': 0.872001051902771, 'learning_rate': 6.896706151055779e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 39000/44659 [2:43:54<23:05,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3554, 'grad_norm': 0.8679773807525635, 'learning_rate': 6.336908573859693e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 39500/44659 [2:45:53<21:12,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3534, 'grad_norm': 0.8325490355491638, 'learning_rate': 5.777110996663607e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 40000/44659 [2:47:53<18:27,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3523, 'grad_norm': 0.7744263410568237, 'learning_rate': 5.21731341946752e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 40239/44659 [2:48:50<17:30,  4.21it/s][INFO|trainer.py:3993] 2025-06-09 18:52:29,354 >> Saving model checkpoint to ./spatial_model/checkpoint-40239\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 18:52:29,358 >> Configuration saved in ./spatial_model/checkpoint-40239/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 18:52:29,360 >> Configuration saved in ./spatial_model/checkpoint-40239/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 18:52:33,857 >> Model weights saved in ./spatial_model/checkpoint-40239/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 18:52:33,869 >> tokenizer config file saved in ./spatial_model/checkpoint-40239/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 18:52:33,870 >> Special tokens file saved in ./spatial_model/checkpoint-40239/special_tokens_map.json\n",
      " 91%|█████████ | 40500/44659 [2:50:30<16:28,  4.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3522, 'grad_norm': 0.7957398295402527, 'learning_rate': 4.657515842271435e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 41000/44659 [2:52:30<14:34,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3508, 'grad_norm': 1.1174373626708984, 'learning_rate': 4.097718265075349e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 41500/44659 [2:54:30<12:30,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.349, 'grad_norm': 0.803623378276825, 'learning_rate': 3.5379206878792628e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 42000/44659 [2:56:29<10:35,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3485, 'grad_norm': 0.6716662049293518, 'learning_rate': 2.978123110683177e-06, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 42500/44659 [2:58:29<08:34,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3492, 'grad_norm': 0.7848895192146301, 'learning_rate': 2.418325533487091e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 43000/44659 [3:00:28<06:37,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3461, 'grad_norm': 0.7589506506919861, 'learning_rate': 1.8585279562910052e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 43500/44659 [3:02:27<04:36,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3469, 'grad_norm': 0.8557010293006897, 'learning_rate': 1.2987303790949193e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 44000/44659 [3:04:26<02:37,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3463, 'grad_norm': 0.7030000686645508, 'learning_rate': 7.389328018988335e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 44500/44659 [3:06:26<00:38,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3442, 'grad_norm': 0.7510824799537659, 'learning_rate': 1.791352247027475e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44659/44659 [3:07:03<00:00,  4.86it/s][INFO|trainer.py:3993] 2025-06-09 19:10:42,617 >> Saving model checkpoint to ./spatial_model/checkpoint-44659\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 19:10:42,621 >> Configuration saved in ./spatial_model/checkpoint-44659/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 19:10:42,631 >> Configuration saved in ./spatial_model/checkpoint-44659/generation_config.json\n",
      "[INFO|modeling_utils.py:3840] 2025-06-09 19:10:47,137 >> Model weights saved in ./spatial_model/checkpoint-44659/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 19:10:47,153 >> tokenizer config file saved in ./spatial_model/checkpoint-44659/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 19:10:47,155 >> Special tokens file saved in ./spatial_model/checkpoint-44659/special_tokens_map.json\n",
      "[INFO|trainer.py:2676] 2025-06-09 19:10:56,136 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 44659/44659 [3:07:17<00:00,  3.97it/s]\n",
      "[INFO|trainer.py:3993] 2025-06-09 19:10:56,145 >> Saving model checkpoint to ./spatial_model\n",
      "[INFO|configuration_utils.py:440] 2025-06-09 19:10:56,150 >> Configuration saved in ./spatial_model/config.json\n",
      "[INFO|configuration_utils.py:891] 2025-06-09 19:10:56,164 >> Configuration saved in ./spatial_model/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11237.5509, 'train_samples_per_second': 15.896, 'train_steps_per_second': 3.974, 'train_loss': 0.7102367408212769, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3840] 2025-06-09 19:11:00,726 >> Model weights saved in ./spatial_model/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2525] 2025-06-09 19:11:00,728 >> tokenizer config file saved in ./spatial_model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2534] 2025-06-09 19:11:00,757 >> Special tokens file saved in ./spatial_model/special_tokens_map.json\n",
      "[INFO|trainer.py:4327] 2025-06-09 19:11:00,902 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4329] 2025-06-09 19:11:00,903 >>   Num examples = 1767\n",
      "[INFO|trainer.py:4332] 2025-06-09 19:11:00,903 >>   Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               = 86940156GF\n",
      "  train_loss               =     0.7102\n",
      "  train_runtime            = 3:07:17.55\n",
      "  train_samples            =     178634\n",
      "  train_samples_per_second =     15.896\n",
      "  train_steps_per_second   =      3.974\n",
      "06/09/2025 19:11:00 - INFO - __main__ - *** Evaluate ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:41<00:00, 10.75it/s]\n",
      "[INFO|modelcard.py:450] 2025-06-09 19:11:42,487 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.8304148887970565}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =     0.8304\n",
      "  eval_loss               =     0.8292\n",
      "  eval_runtime            = 0:00:41.57\n",
      "  eval_samples            =       1767\n",
      "  eval_samples_per_second =     42.506\n",
      "  eval_steps_per_second   =     10.632\n",
      "  perplexity              =     2.2915\n"
     ]
    }
   ],
   "source": [
    "# Train GPT-2 model for one epoch\n",
    "train_model_script(name_or_path='gpt2',\n",
    "                   num_epochs=1,\n",
    "                   output_dir='./spatial_model',\n",
    "                   save_steps=4471,\n",
    "                   lr=5e-05,\n",
    "                   train_batch_size=4,\n",
    "                   eval_batch_size=4,\n",
    "                   block_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d6e26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Check CUDA, MPS, and CPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available. Using CUDA.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"MPS available. Using MPS.\")\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA and MPS not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac0f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Check CUDA, MPS, and CPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available. Using CUDA.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"MPS available. Using MPS.\")\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA and MPS not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7acef5",
   "metadata": {
    "id": "6f7acef5"
   },
   "source": [
    "If resume training is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190ad05e",
   "metadata": {
    "id": "190ad05e"
   },
   "outputs": [],
   "source": [
    "# def resume_training_script(name_or_path='./spatial_model',\n",
    "#                            num_epochs=4,  # Number of additional epochs\n",
    "#                            output_dir='./clm_script',\n",
    "#                            lr=5e-05,\n",
    "#                            train_batch_size=1,\n",
    "#                            eval_batch_size=1,\n",
    "#                            block_size=1024):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     ! python ./run_clm.py \\\n",
    "#         --model_name_or_path {name_or_path} \\\n",
    "#         --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "#         --validation_file {os.path.join(output_dir, 'test.txt')} \\\n",
    "#         --per_device_train_batch_size {train_batch_size} \\\n",
    "#         --per_device_eval_batch_size {eval_batch_size} \\\n",
    "#         --do_train \\\n",
    "#         --do_eval \\\n",
    "#         --output_dir {output_dir} \\\n",
    "#         --overwrite_output_dir \\\n",
    "#         --num_train_epochs {num_epochs} \\\n",
    "#         --save_strategy 'epoch' \\\n",
    "#         --learning_rate {lr} \\\n",
    "#         --block_size {block_size} \\\n",
    "#         --resume_from_checkpoint {name_or_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec63575",
   "metadata": {
    "id": "4ec63575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# # Resume training GPT-2 Large model for more epochs\n",
    "# resume_training_script(name_or_path='./spatial_model',\n",
    "#                        num_epochs=1,  # Train for 2 additional epochs\n",
    "#                        output_dir='./spatial_model_2',\n",
    "#                        lr=5e-05,\n",
    "#                        train_batch_size=1,\n",
    "#                        eval_batch_size=1,\n",
    "#                        block_size=1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed382f9",
   "metadata": {},
   "source": [
    "#### Save Training Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fae1ec0f",
   "metadata": {
    "id": "fae1ec0f"
   },
   "outputs": [],
   "source": [
    "# Path to the directory in your Google Drive where you want to save the file\n",
    "file_path = 'training_output.log'\n",
    "\n",
    "# Open the file in write mode and write the copied output\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# home folder out of space, set environment variables to use a different cache directory\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/cs/student/projects1/aibh/2024/cbaumgar/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/cs/student/projects1/aibh/2024/cbaumgar/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/cs/student/projects1/aibh/2024/cbaumgar/hf_cache\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
