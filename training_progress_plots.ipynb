{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Plots for the Training/Fine-Tuning GPT-2 Model\n",
    "This script plots the progress of training/fine-tuning the GPT-2 model for observation and identification of any anomalies during training. It contains the following parts:\n",
    "\n",
    "* Showing the plot without saving it (for observing progress during training)\n",
    "* Showing the plot and saving it in the working directory\n",
    "\n",
    "To use the script, you need to manually copy the output when you run the train_model_script() in the training script, and paste it in the log_text variable. The script is designed to extract the loss value, gradient norm, and learning rate over the training process (in epochs) and generate the following plots:\n",
    "\n",
    "* Loss over Epochs\n",
    "* Rate of Loss Reduction over Epochs (measured as delta loss in linear scale)\n",
    "* Rate of Loss Reduction over Epochs (measured as delta loss in logarithmic scale)\n",
    "* Gradient Norm over Epochs\n",
    "* Learning Rate Over Epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Plot Only (Not Saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from collections import defaultdict\n",
    "\n",
    "# Your log text (truncated for brevity)\n",
    "log_text = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Regular expressions to find loss, gradient norm, learning rate, and epoch values\n",
    "loss_pattern = re.compile(r\"\\{'loss': ([\\d\\.]+),\")\n",
    "grad_norm_pattern = re.compile(r\"'grad_norm': ([\\d\\.]+),\")\n",
    "lr_pattern = re.compile(r\"'learning_rate': ([\\d\\.e\\-]+),\")\n",
    "epoch_pattern = re.compile(r\"'epoch': ([\\d\\.]+)\\}\")\n",
    "\n",
    "# Extracting the values into dictionaries grouped by epoch\n",
    "data = defaultdict(lambda: {'loss': [], 'grad_norm': [], 'lr': []})\n",
    "\n",
    "# Finding matches and grouping data\n",
    "for match in re.finditer(r\"\\{'loss': ([\\d\\.]+), 'grad_norm': ([\\d\\.]+), 'learning_rate': ([\\d\\.e\\-]+), 'epoch': ([\\d\\.]+)\\}\", log_text):\n",
    "    loss, grad_norm, lr, epoch = map(float, match.groups())\n",
    "    data[epoch]['loss'].append(loss)\n",
    "    data[epoch]['grad_norm'].append(grad_norm)\n",
    "    data[epoch]['lr'].append(lr)\n",
    "\n",
    "# Calculate average values per epoch\n",
    "averaged_data = {\n",
    "    'epoch': sorted(data.keys()),\n",
    "    'loss': [],\n",
    "    'grad_norm': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "for epoch in averaged_data['epoch']:\n",
    "    averaged_data['loss'].append(np.mean(data[epoch]['loss']))\n",
    "    averaged_data['grad_norm'].append(np.mean(data[epoch]['grad_norm']))\n",
    "    averaged_data['lr'].append(np.mean(data[epoch]['lr']))\n",
    "\n",
    "# Extract original and averaged values\n",
    "epoch_values = averaged_data['epoch']\n",
    "loss_values = averaged_data['loss']\n",
    "grad_norm_values = averaged_data['grad_norm']\n",
    "lr_values = averaged_data['lr']\n",
    "\n",
    "original_epoch_values = []\n",
    "original_loss_values = []\n",
    "original_grad_norm_values = []\n",
    "original_lr_values = []\n",
    "\n",
    "for epoch, values in data.items():\n",
    "    original_epoch_values.extend([epoch] * len(values['loss']))\n",
    "    original_loss_values.extend(values['loss'])\n",
    "    original_grad_norm_values.extend(values['grad_norm'])\n",
    "    original_lr_values.extend(values['lr'])\n",
    "\n",
    "# Calculating delta loss from averaged loss values\n",
    "delta_loss = [j - i for i, j in zip(loss_values[:-1], loss_values[1:])]\n",
    "abs_delta_loss = np.abs(delta_loss)\n",
    "\n",
    "# Parameters for Gaussian smoothing\n",
    "sigma = 1  # Standard deviation for Gaussian kernel\n",
    "\n",
    "# Smoothed delta loss using Gaussian filter\n",
    "gaussian_smoothed_delta_loss = gaussian_filter1d(delta_loss, sigma=sigma)\n",
    "\n",
    "# Smoothed absolute delta loss using Gaussian filter\n",
    "gaussian_smoothed_abs_delta_loss = gaussian_filter1d(abs_delta_loss, sigma=sigma)\n",
    "\n",
    "# Smoothed gradient norm using Gaussian filter\n",
    "gaussian_smoothed_grad_norm = gaussian_filter1d(grad_norm_values, sigma=sigma)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 30))  # Increased height for better visibility\n",
    "\n",
    "# Plot for Loss\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.scatter(original_epoch_values, original_loss_values, label='Original Loss', color='tab:grey', alpha=0.5, s=3)\n",
    "plt.plot(epoch_values, loss_values, label='Loss (Averaged Duplicates)', color='tab:red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Delta Loss on a linear scale\n",
    "plt.subplot(5, 1, 2)\n",
    "plt.plot(epoch_values[1:], delta_loss, label='Delta Loss', color='tab:blue', alpha=0.25)\n",
    "plt.plot(epoch_values[1:], gaussian_smoothed_delta_loss, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Delta Loss')\n",
    "plt.title('Rate of Loss Reduction over Epochs (Linear Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Absolute Delta Loss with Gaussian smoothing on a logarithmic scale\n",
    "plt.subplot(5, 1, 3)\n",
    "plt.plot(epoch_values[1:], abs_delta_loss, label='Absolute Delta Loss', color='tab:blue', alpha=0.25)\n",
    "plt.plot(epoch_values[1:], gaussian_smoothed_abs_delta_loss, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Delta Loss (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.title('Rate of Loss Reduction over Epochs (Log Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Gradient Norm\n",
    "plt.subplot(5, 1, 4)\n",
    "plt.scatter(original_epoch_values, original_grad_norm_values, label='Original Gradient Norm', color='tab:grey', alpha=0.5, s=3)\n",
    "plt.plot(epoch_values, grad_norm_values, label='Gradient Norm (Averaged Duplicates)', color='tab:green', alpha=0.25)\n",
    "plt.plot(epoch_values, gaussian_smoothed_grad_norm, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradient Norm over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Learning Rate\n",
    "plt.subplot(5, 1, 5)\n",
    "plt.plot(epoch_values, lr_values, label='Learning Rate', color='tab:orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Show Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from collections import defaultdict\n",
    "\n",
    "# Your log text (truncated for brevity)\n",
    "log_text = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Regular expressions to find loss, gradient norm, learning rate, and epoch values\n",
    "loss_pattern = re.compile(r\"\\{'loss': ([\\d\\.]+),\")\n",
    "grad_norm_pattern = re.compile(r\"'grad_norm': ([\\d\\.]+),\")\n",
    "lr_pattern = re.compile(r\"'learning_rate': ([\\d\\.e\\-]+),\")\n",
    "epoch_pattern = re.compile(r\"'epoch': ([\\d\\.]+)\\}\")\n",
    "\n",
    "# Extracting the values into dictionaries grouped by epoch\n",
    "data = defaultdict(lambda: {'loss': [], 'grad_norm': [], 'lr': []})\n",
    "\n",
    "# Finding matches and grouping data\n",
    "for match in re.finditer(r\"\\{'loss': ([\\d\\.]+), 'grad_norm': ([\\d\\.]+), 'learning_rate': ([\\d\\.e\\-]+), 'epoch': ([\\d\\.]+)\\}\", log_text):\n",
    "    loss, grad_norm, lr, epoch = map(float, match.groups())\n",
    "    data[epoch]['loss'].append(loss)\n",
    "    data[epoch]['grad_norm'].append(grad_norm)\n",
    "    data[epoch]['lr'].append(lr)\n",
    "\n",
    "# Calculate average values per epoch\n",
    "averaged_data = {\n",
    "    'epoch': sorted(data.keys()),\n",
    "    'loss': [],\n",
    "    'grad_norm': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "for epoch in averaged_data['epoch']:\n",
    "    averaged_data['loss'].append(np.mean(data[epoch]['loss']))\n",
    "    averaged_data['grad_norm'].append(np.mean(data[epoch]['grad_norm']))\n",
    "    averaged_data['lr'].append(np.mean(data[epoch]['lr']))\n",
    "\n",
    "# Extract original and averaged values\n",
    "epoch_values = averaged_data['epoch']\n",
    "loss_values = averaged_data['loss']\n",
    "grad_norm_values = averaged_data['grad_norm']\n",
    "lr_values = averaged_data['lr']\n",
    "\n",
    "original_epoch_values = []\n",
    "original_loss_values = []\n",
    "original_grad_norm_values = []\n",
    "original_lr_values = []\n",
    "\n",
    "for epoch, values in data.items():\n",
    "    original_epoch_values.extend([epoch] * len(values['loss']))\n",
    "    original_loss_values.extend(values['loss'])\n",
    "    original_grad_norm_values.extend(values['grad_norm'])\n",
    "    original_lr_values.extend(values['lr'])\n",
    "\n",
    "# Calculating delta loss from averaged loss values\n",
    "delta_loss = [j - i for i, j in zip(loss_values[:-1], loss_values[1:])]\n",
    "abs_delta_loss = np.abs(delta_loss)\n",
    "\n",
    "# Parameters for Gaussian smoothing\n",
    "sigma = 1  # Standard deviation for Gaussian kernel\n",
    "\n",
    "# Smoothed delta loss using Gaussian filter\n",
    "gaussian_smoothed_delta_loss = gaussian_filter1d(delta_loss, sigma=sigma)\n",
    "\n",
    "# Smoothed absolute delta loss using Gaussian filter\n",
    "gaussian_smoothed_abs_delta_loss = gaussian_filter1d(abs_delta_loss, sigma=sigma)\n",
    "\n",
    "# Smoothed gradient norm using Gaussian filter\n",
    "gaussian_smoothed_grad_norm = gaussian_filter1d(grad_norm_values, sigma=sigma)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 30))  # Increased height for better visibility\n",
    "\n",
    "# Plot for Loss\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.scatter(original_epoch_values, original_loss_values, label='Original Loss', color='tab:grey', alpha=0.5, s=3)\n",
    "plt.plot(epoch_values, loss_values, label='Loss (Averaged Duplicates)', color='tab:red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Delta Loss on a linear scale\n",
    "plt.subplot(5, 1, 2)\n",
    "plt.plot(epoch_values[1:], delta_loss, label='Delta Loss', color='tab:blue', alpha=0.25)\n",
    "plt.plot(epoch_values[1:], gaussian_smoothed_delta_loss, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Delta Loss')\n",
    "plt.title('Rate of Loss Reduction over Epochs (Linear Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Absolute Delta Loss with Gaussian smoothing on a logarithmic scale\n",
    "plt.subplot(5, 1, 3)\n",
    "plt.plot(epoch_values[1:], abs_delta_loss, label='Absolute Delta Loss', color='tab:blue', alpha=0.25)\n",
    "plt.plot(epoch_values[1:], gaussian_smoothed_abs_delta_loss, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Delta Loss (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.title('Rate of Loss Reduction over Epochs (Log Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Gradient Norm\n",
    "plt.subplot(5, 1, 4)\n",
    "plt.scatter(original_epoch_values, original_grad_norm_values, label='Original Gradient Norm', color='tab:grey', alpha=0.5, s=3)\n",
    "plt.plot(epoch_values, grad_norm_values, label='Gradient Norm (Averaged Duplicates)', color='tab:green', alpha=0.25)\n",
    "plt.plot(epoch_values, gaussian_smoothed_grad_norm, label=f'Gaussian Smoothed with sigma of {sigma}', color='tab:green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradient Norm over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot for Learning Rate\n",
    "plt.subplot(5, 1, 5)\n",
    "plt.plot(epoch_values, lr_values, label='Learning Rate', color='tab:orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "import os\n",
    "\n",
    "# Saving the plot in specified location\n",
    "directory = ''\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "plt.savefig(os.path.join(directory, 'training_metrics_plot.png'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
