  0%|          | 0/13149 [00:00<?, ?it/s][WARNING|logging.py:328] 2025-07-20 12:58:52,526 >> `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
  4%|▍         | 500/13149 [00:30<12:49, 16.44it/s][INFO|trainer.py:3993] 2025-07-20 12:59:22,805 >> Saving model checkpoint to generalist_model/checkpoint-500
{'loss': 3.9969, 'grad_norm': 1.8737760782241821, 'learning_rate': 4.810251730169595e-05, 'epoch': 0.01}
[INFO|configuration_utils.py:440] 2025-07-20 12:59:22,816 >> Configuration saved in generalist_model/checkpoint-500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 12:59:22,835 >> Configuration saved in generalist_model/checkpoint-500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 12:59:27,170 >> Model weights saved in generalist_model/checkpoint-500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 12:59:27,175 >> tokenizer config file saved in generalist_model/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 12:59:27,191 >> Special tokens file saved in generalist_model/checkpoint-500/special_tokens_map.json
  4%|▍         | 500/13149 [00:41<12:49, 16.44it/s][WARNING|logging.py:328] 2025-07-20 12:59:34,063 >> `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
  8%|▊         | 1000/13149 [01:19<12:14, 16.53it/s][INFO|trainer.py:3993] 2025-07-20 13:00:12,146 >> Saving model checkpoint to generalist_model/checkpoint-1000
{'loss': 3.8115, 'grad_norm': 1.6900736093521118, 'learning_rate': 4.6201232032854214e-05, 'epoch': 0.02}
[INFO|configuration_utils.py:440] 2025-07-20 13:00:12,160 >> Configuration saved in generalist_model/checkpoint-1000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:00:12,163 >> Configuration saved in generalist_model/checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:00:17,056 >> Model weights saved in generalist_model/checkpoint-1000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:00:17,060 >> tokenizer config file saved in generalist_model/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:00:17,068 >> Special tokens file saved in generalist_model/checkpoint-1000/special_tokens_map.json
 11%|█▏        | 1500/13149 [02:09<11:29, 16.89it/s][INFO|trainer.py:3993] 2025-07-20 13:01:02,057 >> Saving model checkpoint to generalist_model/checkpoint-1500
{'loss': 3.7612, 'grad_norm': 1.6611226797103882, 'learning_rate': 4.4299946764012475e-05, 'epoch': 0.02}
[INFO|configuration_utils.py:440] 2025-07-20 13:01:02,060 >> Configuration saved in generalist_model/checkpoint-1500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:01:02,062 >> Configuration saved in generalist_model/checkpoint-1500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:01:05,432 >> Model weights saved in generalist_model/checkpoint-1500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:01:05,435 >> tokenizer config file saved in generalist_model/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:01:05,454 >> Special tokens file saved in generalist_model/checkpoint-1500/special_tokens_map.json
 15%|█▌        | 2000/13149 [03:01<12:42, 14.63it/s][INFO|trainer.py:3993] 2025-07-20 13:01:53,584 >> Saving model checkpoint to generalist_model/checkpoint-2000
{'loss': 3.7321, 'grad_norm': 1.9023892879486084, 'learning_rate': 4.2398661495170736e-05, 'epoch': 0.03}
[INFO|configuration_utils.py:440] 2025-07-20 13:01:53,713 >> Configuration saved in generalist_model/checkpoint-2000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:01:53,762 >> Configuration saved in generalist_model/checkpoint-2000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:01:58,708 >> Model weights saved in generalist_model/checkpoint-2000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:01:58,736 >> tokenizer config file saved in generalist_model/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:01:58,741 >> Special tokens file saved in generalist_model/checkpoint-2000/special_tokens_map.json
 19%|█▉        | 2500/13149 [03:51<10:28, 16.96it/s][INFO|trainer.py:3993] 2025-07-20 13:02:43,458 >> Saving model checkpoint to generalist_model/checkpoint-2500
{'loss': 3.7085, 'grad_norm': 1.826564073562622, 'learning_rate': 4.0497376226328996e-05, 'epoch': 0.04}
[INFO|configuration_utils.py:440] 2025-07-20 13:02:43,464 >> Configuration saved in generalist_model/checkpoint-2500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:02:43,505 >> Configuration saved in generalist_model/checkpoint-2500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:02:47,176 >> Model weights saved in generalist_model/checkpoint-2500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:02:47,188 >> tokenizer config file saved in generalist_model/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:02:47,200 >> Special tokens file saved in generalist_model/checkpoint-2500/special_tokens_map.json
 23%|██▎       | 3000/13149 [04:39<10:15, 16.48it/s][INFO|trainer.py:3993] 2025-07-20 13:03:31,354 >> Saving model checkpoint to generalist_model/checkpoint-3000
{'loss': 3.6847, 'grad_norm': 1.7486915588378906, 'learning_rate': 3.8596090957487264e-05, 'epoch': 0.05}
[INFO|configuration_utils.py:440] 2025-07-20 13:03:31,369 >> Configuration saved in generalist_model/checkpoint-3000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:03:31,374 >> Configuration saved in generalist_model/checkpoint-3000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:03:34,928 >> Model weights saved in generalist_model/checkpoint-3000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:03:34,939 >> tokenizer config file saved in generalist_model/checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:03:34,942 >> Special tokens file saved in generalist_model/checkpoint-3000/special_tokens_map.json
 27%|██▋       | 3500/13149 [05:26<09:42, 16.55it/s][INFO|trainer.py:3993] 2025-07-20 13:04:18,970 >> Saving model checkpoint to generalist_model/checkpoint-3500
{'loss': 3.6709, 'grad_norm': 1.8253268003463745, 'learning_rate': 3.669480568864553e-05, 'epoch': 0.05}
[INFO|configuration_utils.py:440] 2025-07-20 13:04:18,975 >> Configuration saved in generalist_model/checkpoint-3500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:04:18,978 >> Configuration saved in generalist_model/checkpoint-3500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:04:22,385 >> Model weights saved in generalist_model/checkpoint-3500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:04:22,390 >> tokenizer config file saved in generalist_model/checkpoint-3500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:04:22,408 >> Special tokens file saved in generalist_model/checkpoint-3500/special_tokens_map.json
 30%|███       | 4000/13149 [06:14<08:58, 16.99it/s][INFO|trainer.py:3993] 2025-07-20 13:05:06,478 >> Saving model checkpoint to generalist_model/checkpoint-4000
{'loss': 3.6586, 'grad_norm': 1.8973994255065918, 'learning_rate': 3.4793520419803785e-05, 'epoch': 0.06}
[INFO|configuration_utils.py:440] 2025-07-20 13:05:06,501 >> Configuration saved in generalist_model/checkpoint-4000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:05:06,504 >> Configuration saved in generalist_model/checkpoint-4000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:05:10,143 >> Model weights saved in generalist_model/checkpoint-4000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:05:10,156 >> tokenizer config file saved in generalist_model/checkpoint-4000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:05:10,158 >> Special tokens file saved in generalist_model/checkpoint-4000/special_tokens_map.json
 34%|███▍      | 4500/13149 [07:11<10:52, 13.27it/s][INFO|trainer.py:3993] 2025-07-20 13:06:04,061 >> Saving model checkpoint to generalist_model/checkpoint-4500
{'loss': 3.6454, 'grad_norm': 1.9062994718551636, 'learning_rate': 3.289223515096205e-05, 'epoch': 0.07}
[INFO|configuration_utils.py:440] 2025-07-20 13:06:04,077 >> Configuration saved in generalist_model/checkpoint-4500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:06:04,089 >> Configuration saved in generalist_model/checkpoint-4500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:06:07,710 >> Model weights saved in generalist_model/checkpoint-4500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:06:07,723 >> tokenizer config file saved in generalist_model/checkpoint-4500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:06:07,725 >> Special tokens file saved in generalist_model/checkpoint-4500/special_tokens_map.json
 38%|███▊      | 5000/13149 [08:06<09:12, 14.75it/s][INFO|trainer.py:3993] 2025-07-20 13:06:58,726 >> Saving model checkpoint to generalist_model/checkpoint-5000
{'loss': 3.6441, 'grad_norm': 1.595266580581665, 'learning_rate': 3.0990949882120314e-05, 'epoch': 0.08}
[INFO|configuration_utils.py:440] 2025-07-20 13:06:58,743 >> Configuration saved in generalist_model/checkpoint-5000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:06:58,760 >> Configuration saved in generalist_model/checkpoint-5000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:07:03,215 >> Model weights saved in generalist_model/checkpoint-5000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:07:03,231 >> tokenizer config file saved in generalist_model/checkpoint-5000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:07:03,232 >> Special tokens file saved in generalist_model/checkpoint-5000/special_tokens_map.json
 42%|████▏     | 5500/13149 [09:05<09:11, 13.86it/s][INFO|trainer.py:3993] 2025-07-20 13:07:58,012 >> Saving model checkpoint to generalist_model/checkpoint-5500
{'loss': 3.6353, 'grad_norm': 1.7704652547836304, 'learning_rate': 2.9089664613278578e-05, 'epoch': 0.08}
[INFO|configuration_utils.py:440] 2025-07-20 13:07:58,018 >> Configuration saved in generalist_model/checkpoint-5500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:07:58,023 >> Configuration saved in generalist_model/checkpoint-5500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:08:01,322 >> Model weights saved in generalist_model/checkpoint-5500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:08:01,326 >> tokenizer config file saved in generalist_model/checkpoint-5500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:08:01,345 >> Special tokens file saved in generalist_model/checkpoint-5500/special_tokens_map.json
 46%|████▌     | 6000/13149 [09:58<08:36, 13.83it/s][INFO|trainer.py:3993] 2025-07-20 13:08:50,522 >> Saving model checkpoint to generalist_model/checkpoint-6000
{'loss': 3.6302, 'grad_norm': 1.5985212326049805, 'learning_rate': 2.7188379344436842e-05, 'epoch': 0.09}
[INFO|configuration_utils.py:440] 2025-07-20 13:08:50,532 >> Configuration saved in generalist_model/checkpoint-6000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:08:50,546 >> Configuration saved in generalist_model/checkpoint-6000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:08:53,841 >> Model weights saved in generalist_model/checkpoint-6000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:08:53,844 >> tokenizer config file saved in generalist_model/checkpoint-6000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:08:53,854 >> Special tokens file saved in generalist_model/checkpoint-6000/special_tokens_map.json
 49%|████▉     | 6500/13149 [10:50<08:13, 13.47it/s][INFO|trainer.py:3993] 2025-07-20 13:09:42,812 >> Saving model checkpoint to generalist_model/checkpoint-6500
{'loss': 3.6252, 'grad_norm': 1.8126612901687622, 'learning_rate': 2.5287094075595103e-05, 'epoch': 0.1}
[INFO|configuration_utils.py:440] 2025-07-20 13:09:42,825 >> Configuration saved in generalist_model/checkpoint-6500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:09:42,842 >> Configuration saved in generalist_model/checkpoint-6500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:09:46,881 >> Model weights saved in generalist_model/checkpoint-6500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:09:46,884 >> tokenizer config file saved in generalist_model/checkpoint-6500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:09:46,885 >> Special tokens file saved in generalist_model/checkpoint-6500/special_tokens_map.json
 53%|█████▎    | 7000/13149 [11:46<06:25, 15.97it/s][INFO|trainer.py:3993] 2025-07-20 13:10:38,247 >> Saving model checkpoint to generalist_model/checkpoint-7000
{'loss': 3.6224, 'grad_norm': 1.7817624807357788, 'learning_rate': 2.3385808806753367e-05, 'epoch': 0.11}
[INFO|configuration_utils.py:440] 2025-07-20 13:10:38,261 >> Configuration saved in generalist_model/checkpoint-7000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:10:38,271 >> Configuration saved in generalist_model/checkpoint-7000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:10:41,867 >> Model weights saved in generalist_model/checkpoint-7000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:10:41,869 >> tokenizer config file saved in generalist_model/checkpoint-7000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:10:41,886 >> Special tokens file saved in generalist_model/checkpoint-7000/special_tokens_map.json
 57%|█████▋    | 7500/13149 [12:37<05:53, 15.97it/s][INFO|trainer.py:3993] 2025-07-20 13:11:29,886 >> Saving model checkpoint to generalist_model/checkpoint-7500
{'loss': 3.6139, 'grad_norm': 1.6318495273590088, 'learning_rate': 2.148452353791163e-05, 'epoch': 0.11}
[INFO|configuration_utils.py:440] 2025-07-20 13:11:29,893 >> Configuration saved in generalist_model/checkpoint-7500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:11:29,906 >> Configuration saved in generalist_model/checkpoint-7500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:11:33,229 >> Model weights saved in generalist_model/checkpoint-7500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:11:33,231 >> tokenizer config file saved in generalist_model/checkpoint-7500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:11:33,232 >> Special tokens file saved in generalist_model/checkpoint-7500/special_tokens_map.json
 61%|██████    | 8000/13149 [13:29<05:57, 14.39it/s][INFO|trainer.py:3993] 2025-07-20 13:12:21,528 >> Saving model checkpoint to generalist_model/checkpoint-8000
{'loss': 3.61, 'grad_norm': 1.7174451351165771, 'learning_rate': 1.9583238269069892e-05, 'epoch': 0.12}
[INFO|configuration_utils.py:440] 2025-07-20 13:12:21,538 >> Configuration saved in generalist_model/checkpoint-8000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:12:21,559 >> Configuration saved in generalist_model/checkpoint-8000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:12:24,941 >> Model weights saved in generalist_model/checkpoint-8000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:12:24,959 >> tokenizer config file saved in generalist_model/checkpoint-8000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:12:24,977 >> Special tokens file saved in generalist_model/checkpoint-8000/special_tokens_map.json
 65%|██████▍   | 8500/13149 [14:22<05:52, 13.18it/s][INFO|trainer.py:3993] 2025-07-20 13:13:14,537 >> Saving model checkpoint to generalist_model/checkpoint-8500
{'loss': 3.61, 'grad_norm': 1.7809234857559204, 'learning_rate': 1.7681953000228156e-05, 'epoch': 0.13}
[INFO|configuration_utils.py:440] 2025-07-20 13:13:14,566 >> Configuration saved in generalist_model/checkpoint-8500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:13:14,582 >> Configuration saved in generalist_model/checkpoint-8500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:13:18,628 >> Model weights saved in generalist_model/checkpoint-8500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:13:18,651 >> tokenizer config file saved in generalist_model/checkpoint-8500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:13:18,670 >> Special tokens file saved in generalist_model/checkpoint-8500/special_tokens_map.json
 68%|██████▊   | 9000/13149 [15:16<04:56, 14.01it/s][INFO|trainer.py:3993] 2025-07-20 13:14:08,915 >> Saving model checkpoint to generalist_model/checkpoint-9000
{'loss': 3.6075, 'grad_norm': 1.934746265411377, 'learning_rate': 1.5780667731386417e-05, 'epoch': 0.14}
[INFO|configuration_utils.py:440] 2025-07-20 13:14:08,919 >> Configuration saved in generalist_model/checkpoint-9000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:14:08,922 >> Configuration saved in generalist_model/checkpoint-9000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:14:12,277 >> Model weights saved in generalist_model/checkpoint-9000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:14:12,294 >> tokenizer config file saved in generalist_model/checkpoint-9000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:14:12,310 >> Special tokens file saved in generalist_model/checkpoint-9000/special_tokens_map.json
 72%|███████▏  | 9500/13149 [16:07<03:39, 16.62it/s][INFO|trainer.py:3993] 2025-07-20 13:14:59,955 >> Saving model checkpoint to generalist_model/checkpoint-9500
{'loss': 3.6058, 'grad_norm': 1.8547159433364868, 'learning_rate': 1.3879382462544683e-05, 'epoch': 0.14}
[INFO|configuration_utils.py:440] 2025-07-20 13:14:59,974 >> Configuration saved in generalist_model/checkpoint-9500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:14:59,992 >> Configuration saved in generalist_model/checkpoint-9500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:15:03,361 >> Model weights saved in generalist_model/checkpoint-9500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:15:03,379 >> tokenizer config file saved in generalist_model/checkpoint-9500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:15:03,395 >> Special tokens file saved in generalist_model/checkpoint-9500/special_tokens_map.json
 76%|███████▌  | 10000/13149 [16:58<03:37, 14.50it/s][INFO|trainer.py:3993] 2025-07-20 13:15:50,987 >> Saving model checkpoint to generalist_model/checkpoint-10000
{'loss': 3.6038, 'grad_norm': 1.971266269683838, 'learning_rate': 1.1978097193702943e-05, 'epoch': 0.15}
[INFO|configuration_utils.py:440] 2025-07-20 13:15:50,999 >> Configuration saved in generalist_model/checkpoint-10000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:15:51,019 >> Configuration saved in generalist_model/checkpoint-10000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:15:56,047 >> Model weights saved in generalist_model/checkpoint-10000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:15:56,058 >> tokenizer config file saved in generalist_model/checkpoint-10000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:15:56,059 >> Special tokens file saved in generalist_model/checkpoint-10000/special_tokens_map.json
 80%|███████▉  | 10500/13149 [17:51<03:01, 14.58it/s][INFO|trainer.py:3993] 2025-07-20 13:16:44,169 >> Saving model checkpoint to generalist_model/checkpoint-10500
{'loss': 3.5973, 'grad_norm': 1.7078293561935425, 'learning_rate': 1.0076811924861207e-05, 'epoch': 0.16}
[INFO|configuration_utils.py:440] 2025-07-20 13:16:44,171 >> Configuration saved in generalist_model/checkpoint-10500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:16:44,177 >> Configuration saved in generalist_model/checkpoint-10500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:16:47,459 >> Model weights saved in generalist_model/checkpoint-10500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:16:47,478 >> tokenizer config file saved in generalist_model/checkpoint-10500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:16:47,479 >> Special tokens file saved in generalist_model/checkpoint-10500/special_tokens_map.json
 84%|████████▎ | 11000/13149 [18:41<02:13, 16.07it/s][INFO|trainer.py:3993] 2025-07-20 13:17:33,614 >> Saving model checkpoint to generalist_model/checkpoint-11000
{'loss': 3.5959, 'grad_norm': 1.837914228439331, 'learning_rate': 8.17552665601947e-06, 'epoch': 0.17}
[INFO|configuration_utils.py:440] 2025-07-20 13:17:33,632 >> Configuration saved in generalist_model/checkpoint-11000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:17:33,634 >> Configuration saved in generalist_model/checkpoint-11000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:17:36,953 >> Model weights saved in generalist_model/checkpoint-11000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:17:36,957 >> tokenizer config file saved in generalist_model/checkpoint-11000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:17:36,959 >> Special tokens file saved in generalist_model/checkpoint-11000/special_tokens_map.json
 87%|████████▋ | 11500/13149 [19:29<01:53, 14.53it/s][INFO|trainer.py:3993] 2025-07-20 13:18:22,209 >> Saving model checkpoint to generalist_model/checkpoint-11500
{'loss': 3.5908, 'grad_norm': 1.9633818864822388, 'learning_rate': 6.274241387177733e-06, 'epoch': 0.17}
[INFO|configuration_utils.py:440] 2025-07-20 13:18:22,213 >> Configuration saved in generalist_model/checkpoint-11500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:18:22,221 >> Configuration saved in generalist_model/checkpoint-11500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:18:25,527 >> Model weights saved in generalist_model/checkpoint-11500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:18:25,529 >> tokenizer config file saved in generalist_model/checkpoint-11500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:18:25,538 >> Special tokens file saved in generalist_model/checkpoint-11500/special_tokens_map.json
 91%|█████████▏| 12000/13149 [20:21<01:18, 14.64it/s][INFO|trainer.py:3993] 2025-07-20 13:19:13,453 >> Saving model checkpoint to generalist_model/checkpoint-12000
{'loss': 3.5886, 'grad_norm': 1.9581273794174194, 'learning_rate': 4.372956118335996e-06, 'epoch': 0.18}
[INFO|configuration_utils.py:440] 2025-07-20 13:19:13,463 >> Configuration saved in generalist_model/checkpoint-12000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:19:13,464 >> Configuration saved in generalist_model/checkpoint-12000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:19:17,339 >> Model weights saved in generalist_model/checkpoint-12000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:19:17,346 >> tokenizer config file saved in generalist_model/checkpoint-12000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:19:17,368 >> Special tokens file saved in generalist_model/checkpoint-12000/special_tokens_map.json
 95%|█████████▌| 12500/13149 [21:14<00:45, 14.28it/s][INFO|trainer.py:3993] 2025-07-20 13:20:07,141 >> Saving model checkpoint to generalist_model/checkpoint-12500
{'loss': 3.584, 'grad_norm': 1.768236756324768, 'learning_rate': 2.471670849494258e-06, 'epoch': 0.19}
[INFO|configuration_utils.py:440] 2025-07-20 13:20:07,146 >> Configuration saved in generalist_model/checkpoint-12500/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:20:07,148 >> Configuration saved in generalist_model/checkpoint-12500/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:20:11,727 >> Model weights saved in generalist_model/checkpoint-12500/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:20:11,757 >> tokenizer config file saved in generalist_model/checkpoint-12500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:20:11,759 >> Special tokens file saved in generalist_model/checkpoint-12500/special_tokens_map.json
 99%|█████████▉| 13000/13149 [22:06<00:09, 15.75it/s][INFO|trainer.py:3993] 2025-07-20 13:20:58,923 >> Saving model checkpoint to generalist_model/checkpoint-13000
{'loss': 3.586, 'grad_norm': 1.6199499368667603, 'learning_rate': 5.703855806525211e-07, 'epoch': 0.2}
[INFO|configuration_utils.py:440] 2025-07-20 13:20:58,943 >> Configuration saved in generalist_model/checkpoint-13000/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:20:58,959 >> Configuration saved in generalist_model/checkpoint-13000/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:21:02,135 >> Model weights saved in generalist_model/checkpoint-13000/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:21:02,137 >> tokenizer config file saved in generalist_model/checkpoint-13000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:21:02,140 >> Special tokens file saved in generalist_model/checkpoint-13000/special_tokens_map.json
100%|██████████| 13149/13149 [22:32<00:00, 16.59it/s][INFO|trainer.py:3993] 2025-07-20 13:21:24,612 >> Saving model checkpoint to generalist_model/checkpoint-13149
[INFO|configuration_utils.py:440] 2025-07-20 13:21:24,632 >> Configuration saved in generalist_model/checkpoint-13149/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:21:24,652 >> Configuration saved in generalist_model/checkpoint-13149/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:21:27,836 >> Model weights saved in generalist_model/checkpoint-13149/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:21:27,851 >> tokenizer config file saved in generalist_model/checkpoint-13149/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:21:27,858 >> Special tokens file saved in generalist_model/checkpoint-13149/special_tokens_map.json
[INFO|trainer.py:2676] 2025-07-20 13:21:34,248 >>

Training completed. Do not forget to share your model on huggingface.co/models =)


100%|██████████| 13149/13149 [22:42<00:00,  9.65it/s]
{'train_runtime': 1369.5504, 'train_samples_per_second': 9.6, 'train_steps_per_second': 9.601, 'train_loss': 3.6538342908087116, 'epoch': 0.2}
[INFO|trainer.py:3993] 2025-07-20 13:21:34,262 >> Saving model checkpoint to generalist_model
[INFO|configuration_utils.py:440] 2025-07-20 13:21:34,289 >> Configuration saved in generalist_model/config.json
[INFO|configuration_utils.py:891] 2025-07-20 13:21:34,304 >> Configuration saved in generalist_model/generation_config.json
[INFO|modeling_utils.py:3840] 2025-07-20 13:21:37,630 >> Model weights saved in generalist_model/model.safetensors
[INFO|tokenization_utils_base.py:2525] 2025-07-20 13:21:37,662 >> tokenizer config file saved in generalist_model/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-07-20 13:21:37,670 >> Special tokens file saved in generalist_model/special_tokens_map.json
***** train metrics *****
  epoch                    =        0.2
  total_flos               =  6399543GF
  train_loss               =     3.6538
  train_runtime            = 0:22:49.55
  train_samples            =      65741
  train_samples_per_second =        9.6
  train_steps_per_second   =      9.601
07/20/2025 13:21:37 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:4327] 2025-07-20 13:21:37,829 >>
***** Running Evaluation *****
[INFO|trainer.py:4329] 2025-07-20 13:21:37,829 >>   Num examples = 1313
[INFO|trainer.py:4332] 2025-07-20 13:21:37,829 >>   Batch size = 1
100%|██████████| 1313/1313 [00:26<00:00, 48.70it/s]
***** eval metrics *****
  epoch                   =        0.2
  eval_accuracy           =      0.239
  eval_loss               =     3.5955
  eval_runtime            = 0:00:26.98
  eval_samples            =       1313
  eval_samples_per_second =     48.661
  eval_steps_per_second   =     48.661
  perplexity              =    36.4336
[INFO|modelcard.py:450] 2025-07-20 13:22:04,829 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.23901596114946483}]}
