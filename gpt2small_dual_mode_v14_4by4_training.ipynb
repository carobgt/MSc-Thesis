{"cells":[{"cell_type":"markdown","id":"4fd5d68a-4289-41f7-838e-495ecf0d995d","metadata":{"id":"4fd5d68a-4289-41f7-838e-495ecf0d995d","tags":[]},"source":["## Training GPT-2 Model on Path Sequences to Perform Navigation Tasks\n","This script trains/fine-tunes a GPT-2 model on path sequences in artificial grid environments with randomly generated nouns representing locations on a grid.\n","\n","This script has the following parts:\n","\n","* Generation of path sequences in artificial environments\n","Optimal paths and suboptimal paths are separately generated in the training data. For optimal paths, the shortest paths from any starting and ending locations are generated, therefore the training data includes all the possible optimal paths. For suboptimal paths, only a subset is randomly selected, because the number of possible suboptimal paths greatly outnumber optimal paths as the grid size increases. \n","\n","* Train/fine-tune GPT-2 model on the generated path sequences\n","\n","\n"]},{"cell_type":"markdown","id":"9ac1a12d-ed03-4a17-960d-0a6863681170","metadata":{"id":"9ac1a12d-ed03-4a17-960d-0a6863681170"},"source":["#### Installation / imports:"]},{"cell_type":"code","execution_count":1,"id":"fa35db41","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25958,"status":"ok","timestamp":1718189337133,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"fa35db41","outputId":"ff0c94f9-a738-4a25-e9fd-6c540bf3027f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/modelling_spatial_navigation/gpt2small_dual_mode_v12_6000_4by4grids\n"]}],"source":["# Connect to Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/modelling_spatial_navigation/gpt2small_dual_mode_v12_6000_4by4grids\""]},{"cell_type":"code","execution_count":null,"id":"658f7a8e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718189337134,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"658f7a8e","outputId":"5eee6ddb-711a-4225-edad-7d6a0d3a2ed9"},"outputs":[],"source":["# python and pip version check\n","! which python\n","! which pip\n","! python --version"]},{"cell_type":"code","execution_count":null,"id":"05917c15-2dc4-4d88-9ab0-5135187faaa3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115609,"status":"ok","timestamp":1718189452740,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"05917c15-2dc4-4d88-9ab0-5135187faaa3","outputId":"41517c41-e718-4497-f78f-4bf66f1cc9d5","scrolled":true,"tags":[]},"outputs":[],"source":["! pip install git+https://github.com/huggingface/transformers --upgrade\n","! pip install accelerate evaluate wonderwords simpletransformers --upgrade\n","! pip install huggingface_hub --upgrade"]},{"cell_type":"markdown","id":"83366812-1e46-4304-a690-d3cadf2cf35e","metadata":{"id":"83366812-1e46-4304-a690-d3cadf2cf35e"},"source":["### Generate training and test data."]},{"cell_type":"code","execution_count":null,"id":"a1b93d3f-dd38-40bf-a3e5-cfce37e89d6c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9539,"status":"ok","timestamp":1715295219867,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-480},"id":"a1b93d3f-dd38-40bf-a3e5-cfce37e89d6c","outputId":"b73380bc-a088-4dc0-9ddb-64484860c646","scrolled":true,"tags":[]},"outputs":[],"source":["import random\n","import pandas as pd\n","import networkx as nx\n","import logging\n","from random import shuffle\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import random\n","import string\n","import os\n","import re\n","import glob\n","import torch\n","from wonderwords import RandomWord\n","import os\n","import gc\n","import pickle\n","from sklearn.linear_model import LinearRegression\n","from scipy.stats import pearsonr\n","from itertools import permutations\n","import logging\n","from random import shuffle\n","from matplotlib import pyplot as plt\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import math\n","\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","Random_Word = RandomWord()\n","\n","# Function to generate a random grid of nouns\n","def create_unique_random_grid(nouns, size):\n","    random_nouns = random.sample(nouns, size * size)\n","    return [random_nouns[i * size:(i + 1) * size] for i in range(size)]\n","\n","# Function to generate all start-end combinations for a given grid\n","def generate_start_end_permutations(size):\n","    combinations = []\n","    for start_x in range(size):\n","        for start_y in range(size):\n","            for end_x in range(size):\n","                for end_y in range(size):\n","                    if (start_x, start_y) != (end_x, end_y):  # Exclude combinations where start == end\n","                        combinations.append(((start_x, start_y), (end_x, end_y)))\n","    return combinations\n","\n","# Function to generate all possible optimal paths for given start-end combinations\n","def generate_path_permutations(combinations):\n","    paths = []\n","    for start, end in combinations:\n","        horizontal_steps = abs(end[1] - start[1])  # Difference in columns\n","        vertical_steps = abs(end[0] - start[0])    # Difference in rows\n","        steps = ['H'] * horizontal_steps + ['V'] * vertical_steps\n","\n","        unique_permutations = set(permutations(steps))\n","\n","        for perm in unique_permutations:\n","            path = [start]\n","            current_pos = list(start)\n","            for step in perm:\n","                if step == 'H':\n","                    current_pos[1] += 1 if end[1] > start[1] else -1\n","                else:  # 'V'\n","                    current_pos[0] += 1 if end[0] > start[0] else -1\n","                path.append(tuple(current_pos))\n","            # Append each path to the paths list\n","            paths.append({'start': start, 'end': end, 'path': path})\n","\n","    return paths\n","\n","# Function to generate nouns\n","def generate_nouns(size):\n","    Random_Word = RandomWord()\n","    nouns = set()\n","    while len(nouns) < size * size:\n","        # Fetching a random noun and replacing spaces with underscores\n","        word = Random_Word.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\")\n","        if word:  # Ensure that 'None' isn't added to the set if no word is returned\n","            nouns.add(word)\n","    return list(nouns)\n","\n","def shuffle_stimuli(stimuli):\n","    random.shuffle(stimuli)\n","    return stimuli\n","\n","def get_direction(prev_coord, coord):\n","    if coord[0] == prev_coord[0]:\n","        if coord[1] > prev_coord[1]:\n","            return \"R\"\n","        else:\n","            return \"L\"\n","    else:\n","        if coord[0] > prev_coord[0]:\n","            return \"D\"\n","        else:\n","            return \"U\"\n","\n","def generate_all_suboptimal_paths(size):\n","\n","    def is_valid_move(start, end):\n","        \"\"\"Check if the move from start to end is valid (adjacent cells).\"\"\"\n","        return abs(start[0] - end[0]) + abs(start[1] - end[1]) == 1\n","\n","    def is_suboptimal(path, start, end):\n","        \"\"\"Check if the path is suboptimal (longer than the Manhattan distance).\"\"\"\n","        optimal_length = abs(end[0] - start[0]) + abs(end[1] - start[1])\n","        return len(path) > optimal_length + 1  # Must be longer than the optimal path\n","\n","    def generate_all_possible_paths(size):\n","        \"\"\"Generate all possible valid paths for a given grid size.\"\"\"\n","        coords = [(x, y) for x in range(size) for y in range(size)]\n","        all_paths = []\n","        for start in coords:\n","            for end in coords:\n","                if start != end:\n","                    queue = [[start]]\n","                    while queue:\n","                        path = queue.pop(0)\n","                        current_pos = path[-1]\n","                        if current_pos == end:\n","                            if is_suboptimal(path, start, end):\n","                                all_paths.append(path)\n","                        else:\n","                            for move in [(0, 1), (1, 0), (0, -1), (-1, 0)]:  # Right, Down, Left, Up\n","                                next_pos = (current_pos[0] + move[0], current_pos[1] + move[1])\n","                                if (0 <= next_pos[0] < size and 0 <= next_pos[1] < size and\n","                                    next_pos not in path and is_valid_move(current_pos, next_pos)):\n","                                    queue.append(path + [next_pos])\n","        return all_paths\n","\n","    \"\"\"Generate all suboptimal paths for a given grid size.\"\"\"\n","    suboptimal_paths = []\n","    all_possible_paths = generate_all_possible_paths(size)\n","    for path in all_possible_paths:\n","        suboptimal_paths.append({'start': path[0], 'end': path[-1], 'path': path})\n","    return suboptimal_paths\n","\n","def get_movement_options(coord, grid_size, prev_coord):\n","    options = [\"U\", \"D\", \"L\", \"R\"]\n","    moves = {\n","        \"U\": (coord[0] - 1, coord[1]),\n","        \"D\": (coord[0] + 1, coord[1]),\n","        \"L\": (coord[0], coord[1] - 1),\n","        \"R\": (coord[0], coord[1] + 1)\n","    }\n","    valid_moves = []\n","    for option in options:\n","        move = moves[option]\n","        if 0 <= move[0] < grid_size and 0 <= move[1] < grid_size and move != prev_coord:\n","            valid_moves.append(option)\n","        else:\n","            valid_moves.append(\"NA\")\n","    return f\"[{' '.join(valid_moves)}]\"\n","\n","def generate_shortest_path_string(grid, path_coords, probability):\n","    if not path_coords:\n","        return \"\"\n","\n","    size = len(grid)\n","    start, end = path_coords[0], path_coords[-1]\n","    path_string = f\"MODE: Shortest, START: {grid[start[0]][start[1]]}, END: {grid[end[0]][end[1]]}, PATH: \"\n","    prev_coord = None\n","    first_step = True\n","\n","    for i, coord in enumerate(path_coords):\n","        if coord == start:\n","            path_string += grid[start[0]][start[1]]\n","        else:\n","            direction = get_direction(prev_coord, coord)\n","            if first_step:\n","                movement_options = get_movement_options(prev_coord, size, path_coords[i - 2] if i > 1 else None)\n","                path_string += f\" {movement_options} {direction}\"\n","                first_step = False\n","            else:\n","                path_string += f\" {direction}\"\n","\n","            if coord == end:\n","                path_string += f\" {grid[coord[0]][coord[1]]}\"\n","            else:\n","                if random.random() < probability:\n","                    path_string += f\" {grid[coord[0]][coord[1]]}\"\n","                else:\n","                    path_string += \" FORGOT\"\n","\n","        prev_coord = coord\n","\n","    return path_string\n","\n","def generate_foraging_path_string(grid, path_coords, probability):\n","    if not path_coords:\n","        return \"\"\n","\n","    size = len(grid)\n","    start, end = path_coords[0], path_coords[-1]\n","    path_string = f\"MODE: Foraging, START: {grid[start[0]][start[1]]}, END: {grid[end[0]][end[1]]}, PATH: \"\n","    prev_coord = None\n","    first_step = True\n","\n","    for i, coord in enumerate(path_coords):\n","        if coord == start:\n","            path_string += grid[start[0]][start[1]]\n","        else:\n","            direction = get_direction(prev_coord, coord)\n","            if first_step:\n","                movement_options = get_movement_options(prev_coord, size, path_coords[i - 2] if i > 1 else None)\n","                path_string += f\" {movement_options} {direction}\"\n","                first_step = False\n","            else:\n","                path_string += f\" {direction}\"\n","\n","            if coord == end:\n","                path_string += f\" {grid[coord[0]][coord[1]]}\"\n","            else:\n","                if random.random() < probability:\n","                    path_string += f\" {grid[coord[0]][coord[1]]}\"\n","                else:\n","                    path_string += \" FORGOT\"\n","\n","        prev_coord = coord\n","\n","    return path_string\n","\n","size = 4  # Grid size\n","shortest_paths_iterations = 1 # How many times each optimal path is included in the training data\n","num_suboptimal = 744 # How many suboptimal paths to be randomly selected for a single grid environment\n","probability = 0.5 # The probability of forgetting intermediate locations in a given path\n","\n","training_strs = []\n","for i in range(3000): # Number of grid environments in training data\n","    nouns_list = generate_nouns(size)\n","    grid = create_unique_random_grid(nouns_list, size)\n","    start_end_combinations = generate_start_end_permutations(size)\n","\n","    shortest_paths = generate_path_permutations(start_end_combinations)\n","    suboptimal_paths = generate_all_suboptimal_paths(size)\n","\n","    generated_path_strings = []\n","\n","    # Add all shortest paths for a specified number of times (shortest_paths_iterations) to the list of generated path strings\n","    for _ in range(shortest_paths_iterations):\n","        for path in shortest_paths:\n","            generated_path_strings.append(generate_shortest_path_string(grid, path['path'], probability))\n","\n","    # From all possible subtoptimal paths, randomly select a specified number and add to the list\n","    selected_paths = random.sample(suboptimal_paths, num_suboptimal)\n","    for path in selected_paths:\n","        generated_path_strings.append(generate_foraging_path_string(grid, path['path'], probability))\n","\n","    # Shuffle the list of generated path strings\n","    generated_path_strings = shuffle_stimuli(generated_path_strings)\n","\n","    # Append the generated path strings to the training strings list\n","    training_strs += generated_path_strings\n","\n","    # Print the iteration number\n","    if i % 100 == 0:\n","        print(f\"Iteration {i} completed.\")\n","\n","testing_strs = []\n","for i in range(30): # Number of grid environments in testing data\n","    nouns_list = generate_nouns(size)\n","    grid = create_unique_random_grid(nouns_list, size)\n","    start_end_combinations = generate_start_end_permutations(size)\n","\n","    shortest_paths = generate_path_permutations(start_end_combinations)\n","    suboptimal_paths = generate_all_suboptimal_paths(size)\n","\n","    generated_path_strings = []\n","\n","    # Add all shortest paths for a specified number of times (shortest_paths_iterations) to the list of generated path strings\n","    for _ in range(shortest_paths_iterations):\n","        for path in shortest_paths:\n","            generated_path_strings.append(generate_shortest_path_string(grid, path['path'], probability))\n","\n","    # From all possible subtoptimal paths, randomly select a specified number and add to the list\n","    selected_paths = random.sample(suboptimal_paths, num_suboptimal)\n","    for path in selected_paths:\n","        generated_path_strings.append(generate_foraging_path_string(grid, path['path'], probability))\n","\n","    # Shuffle the list of generated path strings\n","    generated_path_strings = shuffle_stimuli(generated_path_strings)\n","\n","    # Append the generated path strings to the testing strings list\n","    testing_strs += generated_path_strings\n","\n","# Print the total number of training and testing path strings\n","print(f\"\\n{len(training_strs)} paths generated for pre-training.\")\n","print(f\"{len(testing_strs)} paths generated for testing.\")"]},{"cell_type":"markdown","id":"f61e5c52-5e6a-4769-983b-23a1117d1c08","metadata":{"id":"f61e5c52-5e6a-4769-983b-23a1117d1c08"},"source":["Write training and testing data into .txt files, and count number of tokens:"]},{"cell_type":"code","execution_count":7,"id":"9039427a-4609-4b49-b39c-ce4cbedccaf9","metadata":{"id":"9039427a-4609-4b49-b39c-ce4cbedccaf9","scrolled":true,"tags":[]},"outputs":[],"source":["!rm -rf spatial_model\n","!mkdir spatial_model\n","\n","text_file = open(\"spatial_model/train.txt\", \"w\")\n","n = text_file.write('\\n'.join(training_strs))\n","text_file.close()\n","\n","text_file = open(\"spatial_model/test.txt\", \"w\")\n","n = text_file.write('\\n'.join(testing_strs))\n","text_file.close()\n"]},{"cell_type":"markdown","id":"eededfef","metadata":{},"source":["### Train/Fine-Tune GPT-2 Model"]},{"cell_type":"markdown","id":"61dc5469","metadata":{"id":"61dc5469"},"source":["The function below runs a script to fine-tune a gpt-2 model on the arbitrary stimuli.\n","\n","The name_or_path argument is which model to fine-tune from. In the pre-training stage, this will be set to 'gpt2'."]},{"cell_type":"code","execution_count":null,"id":"91455446","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7731,"status":"ok","timestamp":1718189460467,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"91455446","outputId":"8a442527-a130-42c9-cb8d-c5bdb2e0a59f"},"outputs":[],"source":["import random\n","import pandas as pd\n","import networkx as nx\n","import logging\n","from random import shuffle\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import random\n","import string\n","import os\n","import re\n","import glob\n","import torch\n","from wonderwords import RandomWord\n","import os\n","import gc\n","import pickle\n","from sklearn.linear_model import LinearRegression\n","from scipy.stats import pearsonr\n","from itertools import permutations\n","import logging\n","from random import shuffle\n","from matplotlib import pyplot as plt\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import math\n","\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Check CUDA, MPS, and CPU availability\n","if torch.cuda.is_available():\n","    print(\"CUDA available. Using CUDA.\")\n","    device = torch.device(\"cuda\")\n","\n","elif torch.backends.mps.is_available():\n","    print(\"MPS available. Using MPS.\")\n","    device = torch.device(\"mps\")\n","\n","else:\n","    print(\"CUDA and MPS not available. Using CPU.\")\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"XMzmuqSrZJOj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1718190817599,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"XMzmuqSrZJOj","outputId":"d9f11c2e-0d94-4b63-ab81-6fca970280ba"},"outputs":[],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":4,"id":"953f3e59","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1718189460467,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"953f3e59"},"outputs":[],"source":["def train_model_script(name_or_path='spatial_model',\n","                       num_epochs=1,\n","                       output_dir='./clm_script',\n","                       save_steps=10000,\n","                       lr=5e-05,\n","                       train_batch_size=1,\n","                       eval_batch_size=1,\n","                       block_size=1024):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    ! python ./run_clm.py \\\n","        --model_name_or_path {name_or_path} \\\n","        --train_file {os.path.join(output_dir, 'train.txt')} \\\n","        --validation_file {os.path.join(output_dir, 'test.txt')} \\\n","        --per_device_train_batch_size {train_batch_size} \\\n","        --per_device_eval_batch_size {eval_batch_size} \\\n","        --do_train \\\n","        --do_eval \\\n","        --output_dir {output_dir} \\\n","        --overwrite_output_dir \\\n","        --num_train_epochs {num_epochs} \\\n","        --save_strategy 'steps' \\\n","        --save_steps {save_steps} \\\n","        --learning_rate {lr} \\\n","        --block_size {block_size}\n"]},{"cell_type":"code","execution_count":null,"id":"307af71c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61186823,"status":"ok","timestamp":1718270406876,"user":{"displayName":"Chin Hoi Wong","userId":"07679049059743907704"},"user_tz":-60},"id":"307af71c","outputId":"cd07d104-7052-4cbc-ec6d-3066ed04151d","slideshow":{"slide_type":"slide"}},"outputs":[],"source":["# Train GPT-2 model for one epoch\n","train_model_script(name_or_path='gpt2',\n","                   num_epochs=1,\n","                   output_dir='./spatial_model',\n","                   save_steps=10000,\n","                   lr=5e-05,\n","                   train_batch_size=1,\n","                   eval_batch_size=1,\n","                   block_size=1024)"]},{"cell_type":"markdown","id":"6f7acef5","metadata":{"id":"6f7acef5"},"source":["If resume training is needed"]},{"cell_type":"code","execution_count":null,"id":"190ad05e","metadata":{"id":"190ad05e"},"outputs":[],"source":["def resume_training_script(name_or_path='./spatial_model',\n","                           num_epochs=4,  # Number of additional epochs\n","                           output_dir='./clm_script',\n","                           lr=5e-05,\n","                           train_batch_size=1,\n","                           eval_batch_size=1,\n","                           block_size=1024):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    ! python ./run_clm.py \\\n","        --model_name_or_path {name_or_path} \\\n","        --train_file {os.path.join(output_dir, 'train.txt')} \\\n","        --validation_file {os.path.join(output_dir, 'test.txt')} \\\n","        --per_device_train_batch_size {train_batch_size} \\\n","        --per_device_eval_batch_size {eval_batch_size} \\\n","        --do_train \\\n","        --do_eval \\\n","        --output_dir {output_dir} \\\n","        --overwrite_output_dir \\\n","        --num_train_epochs {num_epochs} \\\n","        --save_strategy 'epoch' \\\n","        --learning_rate {lr} \\\n","        --block_size {block_size} \\\n","        --resume_from_checkpoint {name_or_path}\n"]},{"cell_type":"code","execution_count":null,"id":"4ec63575","metadata":{"id":"4ec63575"},"outputs":[],"source":["# Resume training GPT-2 Large model for more epochs\n","resume_training_script(name_or_path='./spatial_model',\n","                       num_epochs=1,  # Train for 2 additional epochs\n","                       output_dir='./spatial_model_2',\n","                       lr=5e-05,\n","                       train_batch_size=1,\n","                       eval_batch_size=1,\n","                       block_size=1024)\n"]},{"cell_type":"markdown","id":"aed382f9","metadata":{},"source":["#### Save Training Log File"]},{"cell_type":"code","execution_count":1,"id":"fae1ec0f","metadata":{"id":"fae1ec0f"},"outputs":[],"source":["# Path to the directory in your Google Drive where you want to save the file\n","file_path = 'training_output.log'\n","\n","# Open the file in write mode and write the copied output\n","with open(file_path, 'w') as file:\n","    file.write(\"\"\"\n","\n","\n","\n","\"\"\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
